<!--[if IE]><![endif]--><!DOCTYPE html><!--[if IE 8]><html class="no-js ie8 oldie" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#"

    
        itemscope itemtype="http://schema.org/Book http://schema.org/ItemPage"" data-login-url="/accounts/login/"
data-offline-url="/"
data-url="/library/view/data-visualization-with/9781491920565/ch06.html"
data-csrf-cookie="csrfsafari"
data-highlight-privacy=""


  data-user-id="2870136"
  data-user-uuid="fee1bd59-4e02-48a4-a7b4-152ec4c157ac"
  data-username="flankpeter"
  data-account-type="Trial"
  
  data-activated-trial-date="05/04/2018"


  data-archive="9781491920565"
  data-publishers="O&#39;Reilly Media, Inc."



  data-htmlfile-name="ch06.html"
  data-epub-title="Data Visualization with Python and JavaScript" data-debug=0 data-testing=0><![endif]--><!--[if gt IE 8]><!--><html class="no-js" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#"

    
        itemscope itemtype="http://schema.org/Book http://schema.org/ItemPage"" data-login-url="/accounts/login/"
data-offline-url="/"
data-url="/library/view/data-visualization-with/9781491920565/ch06.html"
data-csrf-cookie="csrfsafari"
data-highlight-privacy=""


  data-user-id="2870136"
  data-user-uuid="fee1bd59-4e02-48a4-a7b4-152ec4c157ac"
  data-username="flankpeter"
  data-account-type="Trial"
  
  data-activated-trial-date="05/04/2018"


  data-archive="9781491920565"
  data-publishers="O&#39;Reilly Media, Inc."



  data-htmlfile-name="ch06.html"
  data-epub-title="Data Visualization with Python and JavaScript" data-debug=0 data-testing=0><!--<![endif]--><head><meta charset="utf-8" /><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" /><meta name="author" content="Safari Books Online" /><meta name="format-detection" content="telephone=no"><meta http-equiv="cleartype" content="on"/><meta name="HandheldFriendly" content="True"/><meta name="MobileOptimized" content="320"/><meta name="apple-itunes-app" content="app-id=881697395, app-argument=safaridetail://9781491920565"/><meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, maximum-scale=1.0"/><meta property="twitter:account_id" content="4503599627559754" /><link rel="apple-touch-icon" href="/static/images/apple-touch-icon.0c29511d2d72.png"/><link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"><link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,600,700,900,200italic,300italic,400italic,600italic,700italic,900italic' rel='stylesheet' type='text/css'><title>6. Heavyweight Scraping with Scrapy - Data Visualization with Python and JavaScript</title><link rel="stylesheet" href="/static/CACHE/css/a04cd81b09cd.css" type="text/css" /><link rel="stylesheet" type="text/css" href="/static/css/annotator.ef38b0457d7b.css"/><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css"><style type="text/css" title="ibis-book">
    @charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td,#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content canvas,#sbo-rt-content details,#sbo-rt-content embed,#sbo-rt-content figure,#sbo-rt-content figcaption,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content output,#sbo-rt-content ruby,#sbo-rt-content section,#sbo-rt-content summary,#sbo-rt-content time,#sbo-rt-content mark,#sbo-rt-content audio,#sbo-rt-content video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content details,#sbo-rt-content figcaption,#sbo-rt-content figure,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content section{display:block}#sbo-rt-content div{line-height:1}#sbo-rt-content ol,#sbo-rt-content ul{list-style:none}#sbo-rt-content blockquote,#sbo-rt-content q{quotes:none}#sbo-rt-content blockquote:before,#sbo-rt-content blockquote:after,#sbo-rt-content q:before,#sbo-rt-content q:after{content:none}#sbo-rt-content table{border-collapse:collapse;border-spacing:0}@page{margin:5px !important}#sbo-rt-content p{margin:10px 0 0;line-height:125%;text-align:left}#sbo-rt-content p.byline{text-align:left;margin:-33px auto 35px;font-style:italic;font-weight:bold}#sbo-rt-content div.preface p+p.byline{margin:1em 0 0}#sbo-rt-content div.preface p.byline+p.byline{margin:0}#sbo-rt-content div.sect1>p.byline{margin:-.25em 0 1em}#sbo-rt-content div.sect1>p.byline+p.byline{margin-top:-1em}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link,#sbo-rt-content a{text-decoration:none;color:#8e0012}#sbo-rt-content span.lineannotation{font-style:italic;color:#a62a2a;font-family:serif}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#fff}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important;margin-bottom:30px !important}#sbo-rt-content section[data-type="sect1"] h1{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content section[data-type="sect2"] h2{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content section[data-type="sect3"] h3{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content section[data-type="sect4"] h4{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section[data-type="chapter"]>div>h1,#sbo-rt-content section[data-type="preface"]>div>h1,#sbo-rt-content section[data-type="appendix"]>div>h1,#sbo-rt-content section[data-type="glossary"]>div>h1,#sbo-rt-content section[data-type="bibliography"]>div>h1,#sbo-rt-content section[data-type="index"]>div>h1{font-size:2em;line-height:1;margin-bottom:50px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content span.label,#sbo-rt-content span.keep-together{font-size:inherit;font-weight:inherit}#sbo-rt-content div[data-type="part"] h1{font-size:2em;text-align:center;margin-top:0 !important;margin-bottom:50px;padding:50px 0 10px 0;border-bottom:1px solid #000}#sbo-rt-content img.width-ninety{width:90%}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center !important;margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content figure{margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content div.figure h6{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding-top:10px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.informalfigure{text-align:center !important;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:15px 0 10px 0 !important;border:1px solid #DCDCDC;background-color:#F7F7F7;padding:15px !important;page-break-inside:avoid}#sbo-rt-content aside[data-type="sidebar"]{margin:15px 0 10px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title,#sbo-rt-content aside[data-type="sidebar"] h5{font-weight:bold;font-size:1em;font-family:sans-serif;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar ol,#sbo-rt-content div.sidebar ul,#sbo-rt-content aside[data-type="sidebar"] ol,#sbo-rt-content aside[data-type="sidebar"] ul{margin-left:1.25em !important}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content aside[data-type="sidebar"] figcaption,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div[data-type="tip"],#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div[data-type="note"],#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div[data-type="warning"],#sbo-rt-content div.sidebar div[data-type="caution"],#sbo-rt-content div.sidebar div[data-type="important"]{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content aside[data-type="sidebar"] p.byline{font-size:90%;font-weight:bold;font-style:italic;text-align:center;text-indent:0;margin:5px auto 6px;page-break-after:avoid}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div[data-type="example"]{margin:10px 0 15px 0 !important}#sbo-rt-content div[data-type="example"] h1,#sbo-rt-content div[data-type="example"] h2,#sbo-rt-content div[data-type="example"] h3,#sbo-rt-content div[data-type="example"] h4,#sbo-rt-content div[data-type="example"] h5,#sbo-rt-content div[data-type="example"] h6{font-style:italic;font-weight:normal;text-align:left !important;text-transform:none !important;font-family:serif !important;margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],#sbo-rt-content div[data-type="example"] pre[data-type="screen"]{margin:0}#sbo-rt-content section[data-type="titlepage"]>div>h1{font-size:2em;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content section[data-type="titlepage"] h2,#sbo-rt-content section[data-type="titlepage"] p.subtitle,#sbo-rt-content section[data-type="titlepage"] p[data-type="subtitle"]{font-size:1.3em;font-weight:normal;text-align:center;margin-top:.5em;color:#555}#sbo-rt-content section[data-type="titlepage"]>div>h2[data-type="author"],#sbo-rt-content section[data-type="titlepage"] p.author{font-size:1.3em;font-family:serif !important;font-weight:bold;margin:50px 0 !important;text-align:center}#sbo-rt-content section[data-type="titlepage"] p.edition{text-align:center;text-transform:uppercase;margin-top:2em}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]>div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content ul.stafflist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.stafflist li{list-style-type:none;padding:5px 0}#sbo-rt-content ul.printings li{list-style-type:none}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif !important;font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif !important;margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10px}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif !important}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-style:italic;margin:.75em 0 0 !important}#sbo-rt-content blockquote div.attribution,#sbo-rt-content blockquote p[data-type="attribution"]{margin:5px 0 10px 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p,#sbo-rt-content blockquote p[data-type="attribution"]{font-style:normal;margin-top:5px}#sbo-rt-content blockquote div.attribution p:before,#sbo-rt-content blockquote p[data-type="attribution"]:before{font-style:normal;content:"—";-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div[data-type="footnotes"]{border-top:1px solid black;margin-top:1.5em}#sbo-rt-content sub,#sbo-rt-content sup{font-size:75%;line-height:0;position:relative}#sbo-rt-content sup{top:-.5em}#sbo-rt-content sub{bottom:-.25em}#sbo-rt-content div.refentry p.refname{font-size:1em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin-bottom:5px;overflow:auto;width:100%}#sbo-rt-content div.refentry{width:100%;display:block;margin-top:2em}#sbo-rt-content div.refsynopsisdiv{display:block;clear:both}#sbo-rt-content div.refentry header{page-break-inside:avoid !important;display:block;break-inside:avoid !important;padding-top:0;border-bottom:1px solid #000}#sbo-rt-content div.refsect1 h6{font-size:.9em;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content div.refsect1{margin-top:3em}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important}#sbo-rt-content dd{margin-left:1.5em !important;margin-bottom:.25em}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ul{list-style-type:disc}#sbo-rt-content ul ul{list-style-type:square}#sbo-rt-content ul ul ul{list-style-type:circle}#sbo-rt-content ol{list-style-type:decimal}#sbo-rt-content ol ol{list-style-type:lower-alpha}#sbo-rt-content ol ol ol{list-style-type:lower-roman}#sbo-rt-content ol ul{list-style-type:disc}#sbo-rt-content ol ul ol{list-style-type:decimal}#sbo-rt-content ul ol{list-style-type:decimal}#sbo-rt-content ul ol ul{list-style-type:disc}#sbo-rt-content ol,#sbo-rt-content ul{list-style-position:outside;margin:15px 0 15px 1.25em}#sbo-rt-content ol li,#sbo-rt-content ul li{margin:.5em 0 .65em;line-height:125%}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist,#sbo-rt-content ul.simplelist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.simplelist li{list-style-type:none;padding:5px 0}#sbo-rt-content table.simplelist td{border:none}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content dl.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content dl.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content dl.calloutlist img,#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol>li>ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol>li>ol>li>ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"],#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{margin:30px !important;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip ol,#sbo-rt-content div.tip ul,#sbo-rt-content div[data-type="tip"] ol,#sbo-rt-content div[data-type="tip"] ul,#sbo-rt-content div.note ol,#sbo-rt-content div.note ul,#sbo-rt-content div[data-type="note"] ol,#sbo-rt-content div[data-type="note"] ul,#sbo-rt-content div.warning ol,#sbo-rt-content div.warning ul,#sbo-rt-content div[data-type="warning"] ol,#sbo-rt-content div[data-type="warning"] ul,#sbo-rt-content div[data-type="caution"] ol,#sbo-rt-content div[data-type="caution"] ul,#sbo-rt-content div[data-type="important"] ol,#sbo-rt-content div[data-type="important"] ul{margin-left:1.5em !important}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"]{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="note"] h1,#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1,#sbo-rt-content div[data-type="important"] h6{font-weight:bold;font-size:110%;font-family:sans-serif !important;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div[data-type="note"] h1{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="important"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,#sbo-rt-content div.safarienabled{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3,#sbo-rt-content div.safarienabled h6{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px 0 30px 0 !important;max-width:95%;border:none !important;background:none;display:table !important}#sbo-rt-content div.table,#sbo-rt-content div.informaltable,#sbo-rt-content table{page-break-inside:avoid}#sbo-rt-content tr,#sbo-rt-content tr td{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td,#sbo-rt-content thead th{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif;font-weight:bold}#sbo-rt-content td,#sbo-rt-content th{display:table-cell;padding:.3em;text-align:left;vertical-align:middle;font-size:80%}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title,#sbo-rt-content table caption{font-weight:normal;font-style:italic;font-family:serif;font-size:1em;margin:10px 0 10px 0 !important;padding:0;page-break-after:avoid;text-align:left !important}#sbo-rt-content table code{font-size:smaller}#sbo-rt-content div.equation,#sbo-rt-content div[data-type="equation"]{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title,#sbo-rt-content div[data-type="equation"] h5{font-style:italic;font-weight:normal;font-family:serif !important;font-size:90%;margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{text-indent:0}#sbo-rt-content div.index li{line-height:140%}#sbo-rt-content div.index a.indexterm{color:#8e0012}#sbo-rt-content div.index ul,#sbo-rt-content div[data-type="index"] ul{list-style-type:none;padding-left:0;margin-left:0}#sbo-rt-content div.index ul li{padding-left:0;margin-left:0}#sbo-rt-content div.index ul li ul li{margin-left:1em}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif;text-align:left}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content span.gray{color:#4C4C4C}
    </style><script> // <![CDATA[
    var g = {
      position_cache: {
        
          "chapter": "/api/v1/book/9781491920565/chapter/ch06.html",
          "book_id": "9781491920565",
          "chapter_uri": "ch06.html",
          "position": 0,
          "user_uuid": "fee1bd59-4e02-48a4-a7b4-152ec4c157ac",
          "next_chapter_uri": "/library/view/data-visualization-with/9781491920565/part03.html"
        
      },
      title: "Data Visualization with Python and JavaScript",
      author_list: "Kyran Dale",
      format: "book",
      source: "application/epub+zip",
      is_system_book: true,
      is_public: false,
      loaded_from_server: true,
      allow_scripts: false,
      has_mathml: false,
      show_ios_app_teaser: false
    };
    // ]]></script><script src="/static/js/src/modernizr.js"></script><script>
    
      
       window.PUBLIC_ANNOTATIONS = false;
      

      window.MOBILE_PUBLIC_ANNOTATIONS = false;

    

    
      window.PRIVACY_CONTROL_OVERRIDE = false;
    

    
      window.PRIVACY_CONTROL_SWITCH = true;
    

    
      window.PUBLISHER_PAGES = true;
    

      window.SBO = {
        "constants": {
          "SITB_ENDPOINT": "https://www.safaribooksonline.com/api/v2/sitb/",
          "SEARCH_SELECT_ENDPOINT": "https://www.safaribooksonline.com/api/v2/search/select/",
          "ENABLE_ONLINE_TRAINING": true
        }
      };
  </script><link rel="canonical" href="https://www.safaribooksonline.com/library/view/data-visualization-with/9781491920565/ch06.html"/><meta name="description" content=" Chapter 6. Heavyweight Scraping with Scrapy As your scraping goals get more ambitious, hacking solutions with BeautifulSoup and requests can get very messy very fast. Managing the scraped data as ... "><meta property="og:title" content="6. Heavyweight Scraping with Scrapy" /><meta itemprop="isPartOf" content="/library/view/data-visualization-with/9781491920565/" /><meta itemprop="name" content="6. Heavyweight Scraping with Scrapy" /><meta property="og:url" itemprop="url" content="https://www.safaribooksonline.com/library/view/data-visualization-with/9781491920565/ch06.html" /><meta property="og:site_name" content="Safari" /><meta property="og:image" itemprop="thumbnailUrl" content="https://www.safaribooksonline.com/library/cover/9781491920565/" /><meta property="og:description" itemprop="description" content=" Chapter 6. Heavyweight Scraping with Scrapy As your scraping goals get more ambitious, hacking solutions with BeautifulSoup and requests can get very messy very fast. Managing the scraped data as ... "><meta itemprop="inLanguage" content="en" /><meta itemprop="publisher" content="O&#39;Reilly Media, Inc." /><meta property="og:type" content="book" /><meta property="og:book:isbn" itemprop="isbn" content="9781491920510" /><meta property="og:book:author" itemprop="author" content="Kyran Dale" /><meta property="og:book:tag" itemprop="about" content="JavaScript" /><meta property="og:book:tag" itemprop="about" content="Python" /><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@safari"><script>
    window.ENABLE_BOWERBIRD_COLLECTIONS = true;
  </script><style type="text/css" id="font-styles" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: <%= font_size %> !important; }"></style><style type="text/css" id="font-family" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: <%= font_family %> !important; }"></style><style type="text/css" id="column-width" data-template="#sbo-rt-content { max-width: <%= column_width %>% !important; margin: 0 auto !important; }"></style><noscript><meta http-equiv="refresh" content="0; url=/library/no-js/" /></noscript><script type="text/javascript">
    (function(i,s,o,g,r,a,m) {
      i['GoogleAnalyticsObject']=r;
      i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();
      a=s.createElement(o),m=s.getElementsByTagName(o)[0];
      a.async=1;
      a.src=g;
      m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    var matches = document.cookie.match(/BrowserCookie\s*=\s*([a-f0-9\-]{36})/),
      user_uuid = null;

    if (matches && matches.length === 2) {
      user_uuid = matches[1];
    }

  
    ga('create', 'UA-39299553-7', {'userId': 'fee1bd59-4e02-48a4-a7b4-152ec4c157ac' });
  

  
    
      ga('set', 'dimension1', 'Trial');
    
  

  ga('set', 'dimension6', user_uuid);

  
    ga('set', 'dimension2', 'fee1bd59-4e02-48a4-a7b4-152ec4c157ac');
    
  

  

  

  //enable enhanced link tracking
  ga('require', 'linkid', 'linkid.js');

  // reading interface will track pageviews itself
  if (document.location.pathname.indexOf("/library/view") !== 0) {
    ga('send', 'pageview');
  }
  </script><script>
    (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-5P4V6Z');
  </script><script defer src="/static/js/build/vendor.e2e622a103f9.js"></script><script defer src="/static/js/build/reader.84feb506aa44.js"></script></head>


<body class="reading sidenav nav-collapsed  scalefonts">

    
  
  <noscript> 
    <iframe src="//www.googletagmanager.com/ns.html?id=GTM-5P4V6Z"
            height="0" width="0"
            style="display:none;visibility:hidden">
    </iframe>
  </noscript>
  



    
      <div class="hide working" role="status">
        <div class="working-image"></div>
      </div>
      <div class="sbo-site-nav">
        





<a href="#container" class="skip">Skip to content</a><header class="topbar t-topbar"><nav role="navigation" class="js-site-nav"><ul class="topnav"><li class="t-logo"><a href="/home/" class="l0 None safari-home nav-icn js-keyboard-nav-home"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>Safari Home Icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M4 9.9L4 9.9 4 18 16 18 16 9.9 10 4 4 9.9ZM2.6 8.1L2.6 8.1 8.7 1.9 10 0.5 11.3 1.9 17.4 8.1 18 8.7 18 9.5 18 18.1 18 20 16.1 20 3.9 20 2 20 2 18.1 2 9.5 2 8.7 2.6 8.1Z"/><rect x="10" y="12" width="3" height="7"/><rect transform="translate(18.121320, 10.121320) rotate(-315.000000) translate(-18.121320, -10.121320) " x="16.1" y="9.1" width="4" height="2"/><rect transform="translate(2.121320, 10.121320) scale(-1, 1) rotate(-315.000000) translate(-2.121320, -10.121320) " x="0.1" y="9.1" width="4" height="2"/></g></svg><span>Safari Home</span></a></li><li><a href="/r/" class="t-recommendations-nav l0 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recommendations icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M50 25C50 18.2 44.9 12.5 38.3 11.7 37.5 5.1 31.8 0 25 0 18.2 0 12.5 5.1 11.7 11.7 5.1 12.5 0 18.2 0 25 0 31.8 5.1 37.5 11.7 38.3 12.5 44.9 18.2 50 25 50 31.8 50 37.5 44.9 38.3 38.3 44.9 37.5 50 31.8 50 25ZM25 3.1C29.7 3.1 33.6 6.9 34.4 11.8 30.4 12.4 26.9 15.1 25 18.8 23.1 15.1 19.6 12.4 15.6 11.8 16.4 6.9 20.3 3.1 25 3.1ZM34.4 15.6C33.6 19.3 30.7 22.2 27.1 22.9 27.8 19.2 30.7 16.3 34.4 15.6ZM22.9 22.9C19.2 22.2 16.3 19.3 15.6 15.6 19.3 16.3 22.2 19.2 22.9 22.9ZM3.1 25C3.1 20.3 6.9 16.4 11.8 15.6 12.4 19.6 15.1 23.1 18.8 25 15.1 26.9 12.4 30.4 11.8 34.4 6.9 33.6 3.1 29.7 3.1 25ZM22.9 27.1C22.2 30.7 19.3 33.6 15.6 34.4 16.3 30.7 19.2 27.8 22.9 27.1ZM25 46.9C20.3 46.9 16.4 43.1 15.6 38.2 19.6 37.6 23.1 34.9 25 31.3 26.9 34.9 30.4 37.6 34.4 38.2 33.6 43.1 29.7 46.9 25 46.9ZM27.1 27.1C30.7 27.8 33.6 30.7 34.4 34.4 30.7 33.6 27.8 30.7 27.1 27.1ZM38.2 34.4C37.6 30.4 34.9 26.9 31.3 25 34.9 23.1 37.6 19.6 38.2 15.6 43.1 16.4 46.9 20.3 46.9 25 46.9 29.7 43.1 33.6 38.2 34.4Z"/></g></svg><span>Recommended</span></a></li><li><a href="/playlists/" class="t-queue-nav l0 nav-icn None"><?xml version="1.0" encoding="UTF-8"?><svg width="21px" height="17px" viewBox="0 0 21 17" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><!-- Generator: Sketch 46.2 (44496) - http://www.bohemiancoding.com/sketch --><title>icon_Playlist_sml</title><desc>Created with Sketch.</desc><defs></defs><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="icon_Playlist_sml" fill-rule="nonzero" fill="#000000"><g id="playlist-icon"><g id="Group-6"><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle></g><g id="Group-5" transform="translate(0.000000, 7.000000)"><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect></g><g id="Group-5-Copy" transform="translate(0.000000, 14.000000)"><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect></g></g></g></g></svg><span>
                 Playlists
              </span></a></li><li class="search"><a href="#" class="t-search-nav trigger nav-icn l0" data-dropdown-selector=".searchbox"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>search icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M31.3 0C20.9 0 12.5 8.4 12.5 18.8 12.5 22.5 13.6 25.9 15.4 28.8L1.2 42.9C-0.4 44.5-0.4 47.2 1.2 48.8 2 49.6 3.1 50 4.2 50 5.2 50 6.3 49.6 7.1 48.8L21.2 34.6C24.1 36.5 27.5 37.5 31.3 37.5 41.6 37.5 50 29.1 50 18.8 50 8.4 41.6 0 31.3 0ZM31.3 31.3C24.4 31.3 18.8 25.6 18.8 18.8 18.8 11.9 24.4 6.3 31.3 6.3 38.1 6.3 43.8 11.9 43.8 18.8 43.8 25.6 38.1 31.3 31.3 31.3Z"/></g></svg><span>Search</span></a></li><li class="usermenu dropdown"><a href="#" class="trigger l0 nav-icn nav-dropdown"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>navigation arrow</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M0.1 12.5L9.7 3.1C9.8 3 9.9 3 10 3 10.1 3 10.2 3 10.3 3.1L19.9 12.5C20 12.5 20 12.6 20 12.8 20 12.9 20 13 19.9 13L17 15.9C16.9 16 16.8 16 16.7 16 16.5 16 16.4 16 16.4 15.9L10 9.7 3.6 15.9C3.6 16 3.5 16 3.3 16 3.2 16 3.1 16 3 15.9L0.1 13C0 12.9 0 12.8 0 12.7 0 12.7 0 12.6 0.1 12.5Z"/></g></svg><span>Expand Nav</span></a><div class="drop-content"><ul><li><a href="/history/" class="t-recent-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recent items icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 0C11.2 0 0 11.2 0 25 0 38.8 11.2 50 25 50 38.8 50 50 38.8 50 25 50 11.2 38.8 0 25 0ZM6.3 25C6.3 14.6 14.6 6.3 25 6.3 35.4 6.3 43.8 14.6 43.8 25 43.8 35.4 35.4 43.8 25 43.8 14.6 43.8 6.3 35.4 6.3 25ZM31.8 31.5C32.5 30.5 32.4 29.2 31.6 28.3L27.1 23.8 27.1 12.8C27.1 11.5 26.2 10.4 25 10.4 23.9 10.4 22.9 11.5 22.9 12.8L22.9 25.7 28.8 31.7C29.2 32.1 29.7 32.3 30.2 32.3 30.8 32.3 31.3 32 31.8 31.5Z"/></g></svg><span>History</span></a></li><li><a href="/topics" class="t-topics-link l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 55" width="20" height="20" version="1.1" fill="#4A3C31"><desc>topics icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 55L50 41.262 50 13.762 25 0 0 13.762 0 41.262 25 55ZM8.333 37.032L8.333 17.968 25 8.462 41.667 17.968 41.667 37.032 25 46.538 8.333 37.032Z"/></g></svg><span>Topics</span></a></li><li><a href="/tutorials/" class="l1 nav-icn t-tutorials-nav js-toggle-menu-item None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>tutorials icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M15.8 18.2C15.8 18.2 15.9 18.2 16 18.2 16.1 18.2 16.2 18.2 16.4 18.2 16.5 18.2 16.7 18.1 16.9 18 17 17.9 17.1 17.8 17.2 17.7 17.3 17.6 17.4 17.5 17.4 17.4 17.5 17.2 17.6 16.9 17.6 16.7 17.6 16.6 17.6 16.5 17.6 16.4 17.5 16.2 17.5 16.1 17.4 15.9 17.3 15.8 17.2 15.6 17 15.5 16.8 15.3 16.6 15.3 16.4 15.2 16.2 15.2 16 15.2 15.8 15.2 15.7 15.2 15.5 15.3 15.3 15.4 15.2 15.4 15.1 15.5 15 15.7 14.9 15.8 14.8 15.9 14.7 16 14.7 16.1 14.6 16.3 14.6 16.4 14.6 16.5 14.6 16.6 14.6 16.6 14.6 16.7 14.6 16.9 14.6 17 14.6 17.1 14.7 17.3 14.7 17.4 14.8 17.6 15 17.7 15.1 17.9 15.2 18 15.3 18 15.5 18.1 15.5 18.1 15.6 18.2 15.7 18.2 15.7 18.2 15.7 18.2 15.8 18.2L15.8 18.2ZM9.4 11.5C9.5 11.5 9.5 11.5 9.6 11.5 9.7 11.5 9.9 11.5 10 11.5 10.2 11.5 10.3 11.4 10.5 11.3 10.6 11.2 10.8 11.1 10.9 11 10.9 10.9 11 10.8 11.1 10.7 11.2 10.5 11.2 10.2 11.2 10 11.2 9.9 11.2 9.8 11.2 9.7 11.2 9.5 11.1 9.4 11 9.2 10.9 9.1 10.8 8.9 10.6 8.8 10.5 8.7 10.3 8.6 10 8.5 9.9 8.5 9.7 8.5 9.5 8.5 9.3 8.5 9.1 8.6 9 8.7 8.8 8.7 8.7 8.8 8.6 9 8.5 9.1 8.4 9.2 8.4 9.3 8.2 9.5 8.2 9.8 8.2 10 8.2 10.1 8.2 10.2 8.2 10.3 8.2 10.5 8.3 10.6 8.4 10.7 8.5 10.9 8.6 11.1 8.7 11.2 8.9 11.3 9 11.4 9.1 11.4 9.2 11.4 9.3 11.5 9.3 11.5 9.3 11.5 9.4 11.5 9.4 11.5L9.4 11.5ZM3 4.8C3.1 4.8 3.1 4.8 3.2 4.8 3.4 4.8 3.5 4.8 3.7 4.8 3.8 4.8 4 4.7 4.1 4.6 4.3 4.5 4.4 4.4 4.5 4.3 4.6 4.2 4.6 4.1 4.7 4 4.8 3.8 4.8 3.5 4.8 3.3 4.8 3.1 4.8 3 4.8 2.9 4.7 2.8 4.7 2.6 4.6 2.5 4.5 2.3 4.4 2.2 4.2 2.1 4 1.9 3.8 1.9 3.6 1.8 3.5 1.8 3.3 1.8 3.1 1.8 2.9 1.8 2.7 1.9 2.6 2 2.4 2.1 2.3 2.2 2.2 2.3 2.1 2.4 2 2.5 2 2.6 1.8 2.8 1.8 3 1.8 3.3 1.8 3.4 1.8 3.5 1.8 3.6 1.8 3.8 1.9 3.9 2 4 2.1 4.2 2.2 4.4 2.4 4.5 2.5 4.6 2.6 4.7 2.7 4.7 2.8 4.7 2.9 4.8 2.9 4.8 3 4.8 3 4.8 3 4.8L3 4.8ZM13.1 15.2C13.2 15.1 13.2 15.1 13.2 15.1 13.3 14.9 13.4 14.7 13.6 14.5 13.8 14.2 14.1 14 14.4 13.8 14.7 13.6 15.1 13.5 15.5 13.4 15.9 13.4 16.3 13.4 16.7 13.5 17.2 13.5 17.6 13.7 17.9 13.9 18.2 14.1 18.5 14.4 18.7 14.7 18.9 15 19.1 15.3 19.2 15.6 19.3 15.9 19.4 16.1 19.4 16.4 19.4 17 19.3 17.5 19.1 18.1 19 18.3 18.9 18.5 18.7 18.7 18.5 19 18.3 19.2 18 19.4 17.7 19.6 17.3 19.8 16.9 19.9 16.6 20 16.3 20 16 20 15.8 20 15.6 20 15.4 19.9 15.4 19.9 15.4 19.9 15.4 19.9 15.2 19.9 15 19.8 14.9 19.8 14.8 19.7 14.7 19.7 14.6 19.7 14.4 19.6 14.3 19.5 14.1 19.3 13.7 19.1 13.4 18.7 13.2 18.4 13.1 18.1 12.9 17.8 12.9 17.5 12.8 17.3 12.8 17.1 12.8 16.9L3.5 14.9C3.3 14.9 3.1 14.8 3 14.8 2.7 14.7 2.4 14.5 2.1 14.3 1.7 14 1.4 13.7 1.2 13.3 1 13 0.9 12.6 0.8 12.3 0.7 12 0.7 11.7 0.7 11.4 0.7 11 0.8 10.5 1 10.1 1.1 9.8 1.3 9.5 1.6 9.2 1.8 8.9 2.1 8.7 2.4 8.5 2.8 8.3 3.2 8.1 3.6 8.1 3.9 8 4.2 8 4.5 8 4.6 8 4.8 8 4.9 8.1L6.8 8.5C6.8 8.4 6.8 8.4 6.8 8.4 6.9 8.2 7.1 8 7.2 7.8 7.5 7.5 7.7 7.3 8 7.1 8.4 6.9 8.7 6.8 9.1 6.7 9.5 6.7 10 6.7 10.4 6.8 10.8 6.8 11.2 7 11.5 7.2 11.8 7.5 12.1 7.7 12.4 8 12.6 8.3 12.7 8.6 12.8 8.9 12.9 9.2 13 9.4 13 9.7 13 9.7 13 9.8 13 9.8 13.6 9.9 14.2 10.1 14.9 10.2 15 10.2 15 10.2 15.1 10.2 15.3 10.2 15.4 10.2 15.6 10.2 15.8 10.1 16 10 16.2 9.9 16.4 9.8 16.5 9.6 16.6 9.5 16.8 9.2 16.9 8.8 16.9 8.5 16.9 8.3 16.9 8.2 16.8 8 16.8 7.8 16.7 7.7 16.6 7.5 16.5 7.3 16.3 7.2 16.2 7.1 16 7 15.9 6.9 15.8 6.9 15.7 6.9 15.6 6.8 15.5 6.8L6.2 4.8C6.2 5 6 5.2 5.9 5.3 5.7 5.6 5.5 5.8 5.3 6 4.9 6.2 4.5 6.4 4.1 6.5 3.8 6.6 3.5 6.6 3.2 6.6 3 6.6 2.8 6.6 2.7 6.6 2.6 6.6 2.6 6.5 2.6 6.5 2.5 6.5 2.3 6.5 2.1 6.4 1.8 6.3 1.6 6.1 1.3 6 1 5.7 0.7 5.4 0.5 5 0.3 4.7 0.2 4.4 0.1 4.1 0 3.8 0 3.6 0 3.3 0 2.8 0.1 2.2 0.4 1.7 0.5 1.5 0.7 1.3 0.8 1.1 1.1 0.8 1.3 0.6 1.6 0.5 2 0.3 2.3 0.1 2.7 0.1 3.1 0 3.6 0 4 0.1 4.4 0.2 4.8 0.3 5.1 0.5 5.5 0.8 5.7 1 6 1.3 6.2 1.6 6.3 1.9 6.4 2.3 6.5 2.5 6.6 2.7 6.6 3 6.6 3 6.6 3.1 6.6 3.1 9.7 3.8 12.8 4.4 15.9 5.1 16.1 5.1 16.2 5.2 16.4 5.2 16.7 5.3 16.9 5.5 17.2 5.6 17.5 5.9 17.8 6.2 18.1 6.5 18.3 6.8 18.4 7.2 18.6 7.5 18.6 7.9 18.7 8.2 18.7 8.6 18.7 9 18.6 9.4 18.4 9.8 18.3 10.1 18.2 10.3 18 10.6 17.8 10.9 17.5 11.1 17.3 11.3 16.9 11.6 16.5 11.8 16 11.9 15.7 12 15.3 12 15 12 14.8 12 14.7 12 14.5 11.9 13.9 11.8 13.3 11.7 12.6 11.5 12.5 11.7 12.4 11.9 12.3 12 12.1 12.3 11.9 12.5 11.7 12.7 11.3 12.9 10.9 13.1 10.5 13.2 10.2 13.3 9.9 13.3 9.6 13.3 9.4 13.3 9.2 13.3 9 13.2 9 13.2 9 13.2 9 13.2 8.8 13.2 8.7 13.2 8.5 13.1 8.2 13 8 12.8 7.7 12.6 7.4 12.4 7.1 12 6.8 11.7 6.7 11.4 6.6 11.1 6.5 10.8 6.4 10.6 6.4 10.4 6.4 10.2 5.8 10.1 5.2 9.9 4.5 9.8 4.4 9.8 4.4 9.8 4.3 9.8 4.1 9.8 4 9.8 3.8 9.8 3.6 9.9 3.4 10 3.2 10.1 3 10.2 2.9 10.4 2.8 10.5 2.6 10.8 2.5 11.1 2.5 11.5 2.5 11.6 2.5 11.8 2.6 12 2.6 12.1 2.7 12.3 2.8 12.5 2.9 12.6 3.1 12.8 3.2 12.9 3.3 13 3.5 13.1 3.6 13.1 3.7 13.1 3.8 13.2 3.9 13.2L13.1 15.2 13.1 15.2Z"/></g></svg><span>Tutorials</span></a></li><li class="nav-offers flyout-parent"><a href="#" class="l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>offers icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M35.9 20.6L27 15.5C26.1 15 24.7 15 23.7 15.5L14.9 20.6C13.9 21.1 13.2 22.4 13.2 23.4L13.2 41.4C13.2 42.4 13.9 43.7 14.9 44.2L23.3 49C24.2 49.5 25.6 49.5 26.6 49L35.9 43.6C36.8 43.1 37.6 41.8 37.6 40.8L37.6 23.4C37.6 22.4 36.8 21.1 35.9 20.6L35.9 20.6ZM40 8.2C39.1 7.6 37.6 7.6 36.7 8.2L30.2 11.9C29.3 12.4 29.3 13.2 30.2 13.8L39.1 18.8C40 19.4 40.7 20.6 40.7 21.7L40.7 39C40.7 40.1 41.4 40.5 42.4 40L48.2 36.6C49.1 36.1 49.8 34.9 49.8 33.8L49.8 15.6C49.8 14.6 49.1 13.3 48.2 12.8L40 8.2 40 8.2ZM27 10.1L33.6 6.4C34.5 5.9 34.5 5 33.6 4.5L26.6 0.5C25.6 0 24.2 0 23.3 0.5L16.7 4.2C15.8 4.7 15.8 5.6 16.7 6.1L23.7 10.1C24.7 10.6 26.1 10.6 27 10.1ZM10.1 21.7C10.1 20.6 10.8 19.4 11.7 18.8L20.6 13.8C21.5 13.2 21.5 12.4 20.6 11.9L13.6 7.9C12.7 7.4 11.2 7.4 10.3 7.9L1.6 12.8C0.7 13.3 0 14.6 0 15.6L0 33.8C0 34.9 0.7 36.1 1.6 36.6L8.4 40.5C9.3 41 10.1 40.6 10.1 39.6L10.1 21.7 10.1 21.7Z"/></g></svg><span>Offers & Deals</span></a><ul class="flyout"><li><a href="https://get.oreilly.com/email-signup.html" target="_blank" class="l2 nav-icn"><span>Newsletters</span></a></li></ul></li><li class="nav-highlights"><a href="/u/fee1bd59-4e02-48a4-a7b4-152ec4c157ac/" class="t-highlights-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 35" width="20" height="20" version="1.1" fill="#4A3C31"><desc>highlights icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M13.325 18.071L8.036 18.071C8.036 11.335 12.36 7.146 22.5 5.594L22.5 0C6.37 1.113 0 10.632 0 22.113 0 29.406 3.477 35 10.403 35 15.545 35 19.578 31.485 19.578 26.184 19.578 21.556 17.211 18.891 13.325 18.071L13.325 18.071ZM40.825 18.071L35.565 18.071C35.565 11.335 39.86 7.146 50 5.594L50 0C33.899 1.113 27.5 10.632 27.5 22.113 27.5 29.406 30.977 35 37.932 35 43.045 35 47.078 31.485 47.078 26.184 47.078 21.556 44.74 18.891 40.825 18.071L40.825 18.071Z"/></g></svg><span>Highlights</span></a></li><li><a href="/u/" class="t-settings-nav l1 js-settings nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"/></g></svg><span>Settings</span></a></li><li><a href="https://www.safaribooksonline.com/public/support" class="l1 no-icon">Support</a></li><li><a href="/accounts/logout/" class="l1 no-icon">Sign Out</a></li></ul><ul class="profile"><li><a href="/u/" class="l2 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"/></g></svg><span>Settings</span></a><span class="l2 t-nag-notification"  id="nav-nag" ><strong class="trial-green">6</strong> days left in your trial.
  
  

  
    
      

<a class="" href="/subscribe/">Subscribe</a>.


    
  

  

</span></li><li><a href="https://www.safaribooksonline.com/public/support" class="l2">Support</a></li><li><a href="/accounts/logout/" class="l2">Sign Out</a></li></ul></div></li></ul></nav></header>


      </div>
      <div id="container" class="application">
        
          <div class="nav-container clearfix">
            


            
            
          </div>

          

  <div class="js-toc">
    
      <div class="sbo-reading-menu sbo-menu-top"><section class="sbo-toc-container toc-menu"><a href="#" class="sbo-toc-thumb"><span class="sbo-title ss-list"><h1><div class="visuallyhidden">Table of Contents for </div>
      
      Data Visualization with Python and JavaScript
      
    </h1></span></a><div class="toc-contents"></div></section></div>

    

    <div class="interface-controls interface-controls-top">
      <ul class="interface-control-btns js-bitlist js-reader">
        <li class="js-search-in-archive search-in-archive t-search-in-archive"><a href="#" title="Search in archive" class="js-search-controls search-controls"><span class="icon">Search in book...</span></a><form class="search-archive-bar js-search-form"><input type="search" name="query" placeholder="Search inside this book..." autocomplete="off"></form><div class="search-archive-results"><div class="js-sitb-results-region"></div></div></li><li class="queue-control"><div class="js-content-uri" data-content-uri="/api/v1/book/9781491920565/chapter/ch06.html"><div class="js-collections-dropdown collections-dropdown menu-bit-cards"></div></div></li><li class="js-font-control-panel font-control-activator"><a href="#" data-push-state="false" id="font-controls" title="Change font size" aria-label="Change font size"><span class="icon">Toggle Font Controls</span></a></li><li class="dropdown sharing-controls"><a href="#" class="trigger" data-push-state="false" title="Share" aria-label="Share"><i class="fa fa-share"></i></a><ul class="social-sharing dropdown-menu"><li><a
        class="twitter share-button t-twitter"
        target="_blank"
        aria-label="Share this section on Twitter"
        title="Share this section on Twitter"
      
        href="https://twitter.com/share?url=https://www.safaribooksonline.com/library/view/data-visualization-with/9781491920565/ch06.html&text=Data%20Visualization%20with%20Python%20and%20JavaScript&via=safari"
      ><span>Twitter</span></a></li><li><a
        class="facebook share-button t-facebook"
        target="_blank"
        aria-label="Share this section on Facebook"
        title="Share this section on Facebook"
        href="https://www.facebook.com/sharer/sharer.php?u=https://www.safaribooksonline.com/library/view/data-visualization-with/9781491920565/ch06.html"
      ><span>Facebook</span></a></li><li><a
        class="googleplus share-button t-googleplus"
        target="_blank"
        aria-label="Share this secton on Google Plus"
        title="Share this secton on Google Plus"
        href="https://plus.google.com/share?url=https://www.safaribooksonline.com/library/view/data-visualization-with/9781491920565/ch06.html"
      ><span>Google Plus</span></a></li><li><a
        class="email share-button t-email"
        aria-label="Share this section via email"
        title="Share this section via email"
      
        href="mailto:?subject=Safari: 6.%20Heavyweight%20Scraping%20with%20Scrapy&body=https://www.safaribooksonline.com/library/view/data-visualization-with/9781491920565/ch06.html%0D%0Afrom Data%20Visualization%20with%20Python%20and%20JavaScript%0D%0A"
      ><span>Email</span></a></li></ul></li>
      </ul>
    </div>

    <section role="document">
        
        



 <!--[if lt IE 9]>
  
<![endif]-->



  <script defer src="/static/js/build/djangoMessagesPage.893631b34e7a.js"></script>


        
	  <div class="t-sbo-prev sbo-prev sbo-nav-top">
  
    
      
        <a href="/library/view/data-visualization-with/9781491920565/ch05.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">5. Getting Data off the Web with Python</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-top">
  
    
      
        <a href="/library/view/data-visualization-with/9781491920565/part03.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">III. Cleaning and Exploring Data with Pandas</div>
        </a>
    
  
  </div>



<div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 6. Heavyweight Scraping with Scrapy"><div class="chapter" id="chapter_heavy_scraping">
<h1><span class="label">Chapter 6. </span>Heavyweight Scraping with Scrapy</h1>


<p><a data-type="indexterm" data-primary="Python" data-secondary="Scrapy library for" id="Pscrapy6"></a><a data-type="indexterm" data-primary="web scraping" data-secondary="Scrapy library for" id="WSscrapy6"></a><a data-type="indexterm" data-primary="Scrapy library" data-secondary="vs. BeautifulSoup" data-secondary-sortas="BeautifulSoup" id="idm140319429226176"></a><a data-type="indexterm" data-primary="BeautifulSoup" data-secondary="vs. Scrapy library" data-secondary-sortas="Scrapy library" id="idm140319429224960"></a><a data-type="indexterm" data-primary="data collection" data-secondary="Scrapy library for" id="DCscrap6"></a>As your scraping goals get more ambitious, hacking solutions with BeautifulSoup and requests can get very messy very fast. Managing the scraped data as requests spawn more requests gets tricky, and if your requests are being made synchronously, things start to slow down rapidly.  A whole load of problems you probably hadn’t anticipated start to make themselves known. It’s at this point that you want to turn to a powerful, robust library that solves all these problems and more. And that’s where Scrapy comes in.</p>

<p><a data-type="indexterm" data-primary="Scrapy library" data-secondary="benefits and drawbacks of" id="idm140319429221600"></a>Where BeautifulSoup is a very handy little penknife for fast and dirty scraping, Scrapy is a  Python library that can do large-scale data scrapes with ease. It has all the things you’d expect, like built-in caching (with expiration times), asynchronous requests via Python’s Twisted web framework, User-Agent randomization, and a whole lot more. The price for all this power is a fairly steep learning curve, which this chapter is intended to smooth, using a simple example.  I think Scrapy is a powerful addition to any dataviz toolkit and really opens up possibilities for web data collection, but if you don’t have any need for heavyweight scraping fu right now, it’s fine to assume we’ve collected our Nobel Prize data and proceed to <a data-type="xref" href="part03.html#part_clean_explore">Part III</a>. Otherwise, let’s buckle our seat belts and see what a real scraping engine can do.</p>

<p>In <a data-type="xref" href="ch05.html#get_data_scraping">“Scraping Data”</a>, we managed to scrape a dataset containing all the Nobel Prize winners by name, year, and category. We did a speculative scrape of the winners’ linked biography pages, which showed that extracting the country of nationality was going to be difficult. In this chapter, we’ll set the bar on our Nobel Prize data a bit higher and aim to scrape objects of the form shown in <a data-type="xref" href="#scrapy_target_JSON">Example 6-1</a>.</p>
<div id="scrapy_target_JSON" data-type="example">
<h5><span class="label">Example 6-1. </span>Our targeted Nobel JSON object</h5>

<pre data-type="programlisting" data-code-language="python"><code class="p">{</code>
  <code class="s2">"category"</code><code class="p">:</code> <code class="s2">"Physiology or Medicine"</code><code class="p">,</code>
  <code class="s2">"country"</code><code class="p">:</code> <code class="s2">"Argentina"</code><code class="p">,</code>
  <code class="s2">"date_of_birth': "</code><code class="mi">8</code> <code class="n">October</code> <code class="mi">1927</code><code class="s2">",</code>
  <code class="s2">"date_of_death': "</code><code class="mi">24</code> <code class="n">March</code> <code class="mi">2002</code><code class="s2">",</code>
  <code class="s2">"gender"</code><code class="p">:</code> <code class="s2">"male"</code><code class="p">,</code>
  <code class="s2">"link"</code><code class="p">:</code> <code class="s2">"http:\/\/en.wikipedia.org\/wiki\/C%C3%A9sar_Milstein"</code><code class="p">,</code>
  <code class="s2">"name"</code><code class="p">:</code> <code class="s2">"C</code><code class="se">\u00e9</code><code class="s2">sar Milstein"</code><code class="p">,</code>
  <code class="s2">"place_of_birth"</code><code class="p">:</code> <code class="s2">"Bah</code><code class="se">\u00ed</code><code class="s2">a Blanca ,  Argentina"</code><code class="p">,</code>
  <code class="s2">"place_of_death"</code><code class="p">:</code> <code class="s2">"Cambridge , England"</code><code class="p">,</code>
  <code class="s2">"text"</code><code class="p">:</code> <code class="s2">"C</code><code class="se">\u00e9</code><code class="s2">sar Milstein , Physiology or Medicine, 1984"</code><code class="p">,</code>
  <code class="s2">"year"</code><code class="p">:</code> <code class="mi">1984</code>
<code class="p">}</code></pre></div>

<p>In addition to this data, we’ll aim to scrape prize winners’ photos (where applicable) and some potted biographical data (see <a data-type="xref" href="#scrapy_targets">Figure 6-1</a>). We’ll be using the photos and body text to add a little character to our Nobel Prize visualization.</p>

<figure><div id="scrapy_targets" class="figure">
<img src="dvpj_0601.png" alt="dvpj 0601" width="1103" height="778">
<h6><span class="label">Figure 6-1. </span>Scraping targets for the prize winners’ pages</h6>
</div></figure>






<section data-type="sect1" data-pdf-bookmark="Setting Up Scrapy"><div class="sect1" id="idm140319429042880">
<h1>Setting Up Scrapy</h1>

<p><a data-type="indexterm" data-primary="Scrapy library" data-secondary="setting up" id="idm140319429041280"></a>Scrapy should be one of the Anaconda packages (see <a data-type="xref" href="ch01.html#chapter_install">Chapter 1</a>) so you should already have it on hand. If that’s not the case, then you can install it with the following <code>conda</code> command line:</p>

<pre data-type="programlisting">$ conda install -c https://conda.anaconda.org/anaconda scrapy</pre>

<p>If you’re not using Anaconda, a quick <code>pip</code> install will do the job:<sup><a data-type="noteref" id="idm140319429037248-marker" href="ch06.html#idm140319429037248">1</a></sup></p>

<pre data-type="programlisting">$ pip install scrapy</pre>

<p>With Scrapy installed, you should have access to the <code>scrapy</code> command. Unlike the vast majority of Python libraries, Scrapy is designed to be driven from the command line within the context of a scraping project, defined by configuration files, scraping spiders, pipelines, and so on. Let’s generate a fresh project for our Nobel Prize scraping, using the <code>startproject</code> option. This is going to generate a project folder, so make sure you run it from a suitable work <span class="keep-together">directory</span>:</p>

<pre data-type="programlisting" data-code-language="bash"><code class="nv">$ </code>scrapy startproject nobel_winners
New Scrapy project <code class="s1">'nobel_winners'</code> created in:
    /home/kyran/workspace/.../scrapy/nobel_winners

You can start your first spider with:
    <code class="nb">cd </code>nobel_winners
    scrapy genspider example example.com</pre>

<p>As the output of <code>startproject</code> says, you’ll want to switch to the <em>nobel_winners</em> directory in order to start driving Scrapy.</p>

<p>Let’s take a look at the project’s directory tree:</p>

<pre data-type="programlisting" data-code-language="bash">nobel_winners
├── nobel_winners
│   ├── __init__.py
│   ├── items.py
│   ├── pipelines.py
│   ├── settings.py
│   └── spiders
│       └── __init__.py
└── scrapy.cfg</pre>

<p>As shown, the project directory has a subdirectory with the same name and a config file <em>scrapy.cfg</em>. The <em>nobel_winners</em> subdirectory is a Python module (containing an <em>__init__.py</em> file) with a few skeleton files and a <em>spiders</em> directory, which will contain your scrapers.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Establishing the Targets"><div class="sect1" id="idm140319429042256">
<h1>Establishing the Targets</h1>

<p><a data-type="indexterm" data-primary="Scrapy library" data-secondary="establishing targets" id="idm140319428978624"></a>In <a data-type="xref" href="ch05.html#get_data_scraping">“Scraping Data”</a>, we tried to scrape the Nobel winners’ nationalities from their biography pages but found they were missing or inconsistently labeled in many cases (see <a data-type="xref" href="ch05.html#chapter_getting_data">Chapter 5</a>). Rather than get the country data indirectly, a little  Wikipedia searching shows a way through. There is a <a href="http://en.wikipedia.org/wiki/List_of_Nobel_laureates_by_country">page</a> that lists winners by country. The winners are presented in titled, ordered lists (see <a data-type="xref" href="#scrapy_wiki_list">Figure 6-2</a>), not in tabular form, which makes recovering our basic name, category, and year data a little harder. Also the data organization is not ideal (e.g., the country header titles and winner lists aren’t in useful, separate blocks). As we’ll see, a few well-structured Scrapy queries will easily net us the data we need.</p>

<p><a data-type="xref" href="#scrapy_wiki_list">Figure 6-2</a> shows the starting page for our first spider along with the key elements it will be targeting. A list of country name titles (A) is followed by an ordered list (B) of their Nobel Prize–winning <span class="keep-together">citizens</span>.</p>

<p>In order to scrape the list data, we need to fire up our Chrome browser’s development tools (see <a data-type="xref" href="ch04.html#chrome_elements">“The Elements Tab”</a>) and inspect the target elements using the Elements tab and its inspector (magnifying glass). <a data-type="xref" href="#scrapy_wiki_list_source">Figure 6-3</a> shows the key HTML targets for our first spider: header titles (<code>h2</code>) containing a country name and followed by an ordered list (<code>ol</code>) of winners (<code>li</code>).</p>

<figure><div id="scrapy_wiki_list" class="figure">
<img src="dvpj_0602.png" alt="dvpj 0602" width="1565" height="1044">
<h6><span class="label">Figure 6-2. </span>Scraping Wikipedia’s Nobel Prizes by nationality</h6>
</div></figure>

<figure><div id="scrapy_wiki_list_source" class="figure">
<img src="dvpj_0603.png" alt="dvpj 0603" width="1565" height="918">
<h6><span class="label">Figure 6-3. </span>Finding the HTML targets for the wikilist</h6>
</div></figure>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Targeting HTML with Xpaths"><div class="sect1" id="idm140319429022016">
<h1>Targeting HTML with Xpaths</h1>

<p><a data-type="indexterm" data-primary="Scrapy library" data-secondary="targeting HTML with xpaths" id="idm140319429020448"></a><a data-type="indexterm" data-primary="xpaths" data-secondary="targeting HTML with" id="idm140319429019504"></a>Scrapy uses <a href="https://en.wikipedia.org/wiki/XPath">xpaths</a> to define its HTML targets. Xpath is a syntax for describing parts of an X(HT)ML document, and while it can get rather complicated, the basics are straightforward and will often solve the job at hand.</p>

<p>You can get the xpath of an HTML element by using Chrome’s Elements tab to hover over the source and then right-clicking and selecting Copy Xpath. For example, in the case of our Nobel Prize wikilist’s country names (h2 in <a data-type="xref" href="#scrapy_wiki_list_source">Figure 6-3</a>), selecting the xpath of Argentina (the first country) gives the following:</p>

<pre data-type="programlisting">//*[@id="mw-content-text"]/h2[1]</pre>

<p>We can use the following xpath rules to decode it:</p>
<dl>
<dt><code>//E</code></dt>
<dd>
<p>Element <code>&lt;E&gt;</code> anywhere in the document (e.g., <code>//img</code> gets all images on the page)</p>
</dd>
<dt><code>//E[@id="foo"]</code></dt>
<dd>
<p>Select element <code>&lt;E&gt;</code> with id <code>foo</code></p>
</dd>
<dt><code>//*[@id="foo"]</code></dt>
<dd>
<p>Select any element with id <code>foo</code></p>
</dd>
<dt><code>//E/F[1]</code></dt>
<dd>
<p>First child element <code>&lt;F&gt;</code> of element <code>&lt;E&gt;</code></p>
</dd>
<dt><code>//E/*[1]</code></dt>
<dd>
<p>First child of element <code>&lt;E&gt;</code></p>
</dd>
</dl>

<p>Following these rules shows that our Argentinian title <code>//*[@id="mw-content-text"]/h2[1]</code> is the first header (h2) child of a DOM element with id <code>mw-content-text</code>. This is equivalent to the following HTML:</p>

<pre data-type="programlisting" data-code-language="html"><code class="nt">&lt;div</code> <code class="na">id=</code><code class="s">"mw-content-text"</code><code class="nt">&gt;</code>
    <code class="nt">&lt;h2&gt;</code>
        ...
    <code class="nt">&lt;/h2&gt;</code>
    ...
<code class="nt">&lt;/div&gt;</code></pre>

<p>Note that unlike Python, the xpaths don’t use a zero-based index but make the first member <em>1</em>.</p>








<section data-type="sect2" data-pdf-bookmark="Testing Xpaths with the Scrapy Shell"><div class="sect2" id="idm140319429143552">
<h2>Testing Xpaths with the Scrapy Shell</h2>

<p><a data-type="indexterm" data-primary="xpaths" data-secondary="testing with Scrapy shell" id="Xshell6"></a><a data-type="indexterm" data-primary="Scrapy library" data-secondary="Scrapy shell" id="SLxpath6"></a>Getting your xpath targeting right is crucial to good scraping and can involve a degree of iteration. Scrapy makes this process much easier by providing a command-line shell, which takes a URL and creates a response context in which you can try out your xpaths, like so:</p>

<pre data-type="programlisting" data-code-language="bash"><code class="nv">$ </code>scrapy shell
  https://en.wikipedia.org/wiki/
  List_of_Nobel_laureates_by_country


2015-12-15 17:42:12+0000 <code class="o">[</code>scrapy<code class="o">]</code> INFO: Scrapy 0.24.4 started
<code class="o">(</code>bot: nobel_winners<code class="o">)</code>
...
2015-12-15 17:42:12+0000 <code class="o">[</code>default<code class="o">]</code> INFO: Spider opened
2015-12-15 17:42:13+0000 <code class="o">[</code>default<code class="o">]</code> DEBUG: Crawled <code class="o">(</code>200<code class="o">)</code>
&lt;GET https://en.wikip...List_of_Nobel_laureates_by_country&gt;
<code class="o">(</code>referer: None<code class="o">)</code>
<code class="o">[</code>s<code class="o">]</code> Available Scrapy objects:

<code class="o">[</code>s<code class="o">]</code>   crawler  &lt;scrapy.crawler.Crawler object at 0x3a8f510&gt;
<code class="o">[</code>s<code class="o">]</code>   item <code class="o">{}</code>
<code class="o">[</code>s<code class="o">]</code>   request    &lt;GET https://...Nobel_laureates_by_country&gt;
<code class="o">[</code>s<code class="o">]</code>   response   &lt;<code class="m">200</code> https://...Nobel_laureates_by_country&gt;
<code class="o">[</code>s<code class="o">]</code>   settings   &lt;scrapy.settings.Settings object at 0x34a98d0&gt;
<code class="o">[</code>s<code class="o">]</code>   spider     &lt;Spider <code class="s1">'default'</code> at 0x3f59190&gt;

<code class="o">[</code>s<code class="o">]</code> Useful shortcuts:
<code class="o">[</code>s<code class="o">]</code>   shelp<code class="o">()</code>   Shell <code class="nb">help</code> <code class="o">(</code>print this <code class="nb">help</code><code class="o">)</code>
<code class="o">[</code>s<code class="o">]</code>   fetch<code class="o">(</code>req_or_url<code class="o">)</code> Fetch request <code class="o">(</code>or URL<code class="o">)</code> and update <code class="nb">local</code>
objects
<code class="o">[</code>s<code class="o">]</code>   view<code class="o">(</code>response<code class="o">)</code>    View response in a browser

In <code class="o">[</code>1<code class="o">]</code>:</pre>

<p>Now we have an IPython-based shell with code-complete and syntax highlighting in which to try out our xpath targeting. Let’s grab all the <code>&lt;h2&gt;</code> headers on the wiki page:</p>

<pre data-type="programlisting">In [1]: h2s = response.xpath('//h2')</pre>

<p>The resulting <code>h2s</code> is a <a href="http://doc.scrapy.org/en/latest/topics/selectors.html#scrapy.selector.SelectorList">SelectorList</a>, a specialized Python <code>list</code> object. Let’s see how many headers we have:</p>

<pre data-type="programlisting">In [2]: len(h2s)
Out[2]: 76</pre>

<p>We can grab the first <a href="http://doc.scrapy.org/en/latest/topics/selectors.html#topics-selectors-ref">Selector</a> object and query its methods and properties in the Scrapy shell by pressing Tab after appending a dot:</p>

<pre data-type="programlisting">In [3] h2 = h2s[0]
In [4] h2.
h2.css            h2.namespaces     h2.remove_namespaces
h2.text           h2.extract        h2.re
h2.response       h2.type           h2.register_namespace
h2.select         h2.xpath</pre>

<p>You’ll often use the <code>extract</code> method to get the raw result of the xpath selector:</p>

<pre data-type="programlisting">In [5]: h2.extract()
Out[5]: u'&lt;h2&gt;Contents&lt;/h2&gt;'</pre>

<p>This shows that our first <code>&lt;h2&gt;</code> header is that of the table of contents for our list of winners by country. Let’s look at the second header:</p>

<pre data-type="programlisting">In [6]: h2s[1].extract()
Out[6]:
u'&lt;h2&gt;
  &lt;span class="mw-headline" id="Argentina"&gt;Argentina&lt;/span&gt;
  &lt;span class="mw-editsection"&gt;
  &lt;span class="mw-editsection-bracket"&gt;
  ...
  &lt;/h2&gt;'</pre>

<p>This shows that our country headers start on the second <code>&lt;h2&gt;</code> and contain a <code>span</code> with class <code>mw-headline</code>. We can use the presence of the <code>mw-headline</code> class as a filter for our country headers and the contents as our country label. Let’s try out an xpath, using the selector’s <code>text</code> method to extract the text from the <code>mw-headline</code> span. Note that we use the <code>xpath</code> method of the <code>&lt;h2&gt;</code> selector, which makes the xpath query relative to that element.</p>

<pre data-type="programlisting">In [7]: h2_arg = h2s[1]
In [8]: country = h2_arg.xpath(\
                         'span[@class="mw-headline"]/text()')\
.extract()
In [9]: country
Out[9]: [u'Argentina']</pre>

<p>The <code>extract</code> method returns a list of possible matches, in our case the single <code>'Argentina'</code> string. By iterating through the <code>h2s</code> list, we can now get our country names.</p>

<p>Assuming we have a country’s <code>&lt;h2&gt;</code> header, we now need to get the <code>&lt;ol&gt;</code> ordered list of Nobel winners following it (<a data-type="xref" href="#scrapy_wiki_list">Figure 6-2</a>  B). Handily, the xpath <code>following-sibling</code> selector can do just that. Let’s grab the first ordered list after the Argentina header:</p>

<pre data-type="programlisting">In [10]: ol_arg = h2_arg.xpath('following-sibling::ol[1]')
Out[10]: ol_arg
[&lt;Selector xpath='following-sibling::ol[1]' data=u'&lt;ol&gt;\n&lt;li&gt;
&lt;a href="/wiki/C%C3%A9sar_Milst'&gt;]</pre>

<p>Looking at the truncated data for <code>ol_arg</code> shows that we have selected an ordered list.  Note that even though there’s only one <code>Selector</code>, <code>xpath</code> still returns a <code>SelectorList</code>.  For convenience, you’ll generally just select the first member directly:</p>

<pre data-type="programlisting">In [11]: ol_arg = h2_arg.xpath('following-sibling::ol[1]')[0]</pre>

<p>Now that we’ve got the ordered list, let’s get a list of its member <code>&lt;li&gt;</code> elements:</p>

<pre data-type="programlisting">In [12]: lis_arg = ol_arg.xpath('li')
In [13]: len(lis_arg)
Out[13]: 5</pre>

<p>Let’s examine one of those list elements using <code>extract</code>. As a first test, we’re looking to scrape the name of the winner and capture the list element’s text.</p>

<pre data-type="programlisting">In [14]: li = lis_arg[0] # select the first list element
In [15]: li.extract()
Out[15]:
u'&lt;li&gt;&lt;a href="/wiki/C%C3%A9sar_Milstein"
         title="C\xe9sar Milstein"&gt;C\xe9sar Milstein&lt;/a&gt;,
         Physiology or Medicine, 1984&lt;/li&gt;'</pre>

<p>Extracting the list element shows a standard pattern: a hyperlinked name to the winner’s Wikipedia page followed by a comma-separated winning category and year. A robust way to get the winning name is just to select the text of the list element’s first <code>&lt;a&gt;</code> tag:</p>

<pre data-type="programlisting">In [16]: name = li.xpath('a//text()')[0].extract()
In [17]: name
Out[17]: u'C\xe9sar Milstein'</pre>

<p>It’s often useful to get all the text in, for example, a list element, stripping the various HTML <code>&lt;a&gt;</code>, <code>&lt;span&gt;</code>, and other tags. <code>descendent-or-self</code> gives us a handy way of doing this, producing a list of the descendents’ text:</p>

<pre data-type="programlisting">In [18]: list_text = li.xpath('descendant-or-self::text()')\
.extract()
In [19]: list_text
Out[19]: [u'C\xe9sar Milstein', u', Physiology or Medicine,'\
'1984']</pre>

<p>We can get the full text by joining the list elements together:</p>

<pre data-type="programlisting">In [20]: ' '.join(list_text)
Out[20]: u'C\xe9sar Milstein , Physiology or Medicine, 1984'</pre>

<p>Note that the first item of <code>list_text</code> is the winner’s name, giving us another way to access it if, for example, it were missing a hyperlink.</p>

<p>Now that we’ve established the xpaths to our scraping targets (the name and link text of the Nobel Prize winners), let’s incorporate them into our first Scrapy spider.<a data-type="indexterm" data-primary="" data-startref="SLxpath6" id="idm140319428870000"></a><a data-type="indexterm" data-primary="" data-startref="Xshell6" id="idm140319428869024"></a></p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Selecting with Relative Xpaths"><div class="sect2" id="idm140319429169200">
<h2>Selecting with Relative Xpaths</h2>

<p><a data-type="indexterm" data-primary="Scrapy library" data-secondary="selecting with relative xpaths" id="idm140319428866960"></a><a data-type="indexterm" data-primary="xpaths" data-secondary="selecting with relative" id="idm140319428865920"></a>As just shown, Scrapy <code>xpath</code> selections return lists of selectors which, in turn,  have their own <code>xpath</code> methods. When using the <code>xpath</code> method, it’s important to be clear about relative and absolute selections. Let’s make the distinction clear using the Nobel page’s table of contents as an example.</p>

<p>The table of contents has the following structure:</p>

<pre data-type="programlisting" data-code-language="html"><code class="nt">&lt;div</code> <code class="na">id=</code><code class="s">'toc'</code><code class="err">...</code> <code class="nt">&gt;</code>
   <code class="nt">&lt;ul</code> <code class="err">...</code> <code class="nt">&gt;</code>
     <code class="nt">&lt;li</code> <code class="err">...</code> <code class="nt">&gt;</code>
       <code class="nt">&lt;a</code> <code class="na">href=</code><code class="s">'Argentina'</code><code class="nt">&gt;</code> ... <code class="nt">&lt;/a&gt;</code>
     <code class="nt">&lt;/li&gt;</code>
     ...
   <code class="nt">&lt;/ul&gt;</code>
<code class="nt">&lt;/div&gt;</code></pre>

<p>We can select the table of contents of the Nobel wikipage using a standard <code>xpath</code> query on the response, and getting the <code>div</code> with id <code>toc</code>.</p>

<pre data-type="programlisting">In [21]: toc = response.xpath('//div[@id="toc"]')[0]</pre>

<p>If we want to get all the country <code>&lt;li&gt;</code> list tags, we can use a relative <code>xpath</code> on the selected <code>toc</code> div. The following two are equivalent, both selecting children of the current selection relatively:</p>

<pre data-type="programlisting">In [22]: lis = toc.xpath('.//ul/li')
In [23]: lis = toc.xpath('ul/li')
In [24]: len(lis)
Out[24]: 76 # the number of countries in the table of contents</pre>

<p>A common mistake is to use a nonrelative <code>xpath</code> selector on the current selection, which selects from the whole document, in this case getting all unordered (<code>&lt;ul&gt;</code>) <code>&lt;li&gt;</code> tags:</p>

<pre data-type="programlisting">In [25]: lis = toc.xpath('//ul/li')
In [26]: len(lis)
OUt[26]: 212</pre>

<p>Errors made from mistaking relative and nonrelative queries crop up a lot in the forums, so it’s good to be very aware of the distinction and watch those dots.</p>
<div data-type="tip"><h6>Tip</h6>
<p>Getting the right xpath expression for your target element(s) can be a little tricky, and those difficult edge cases can demand a complex nest of clauses. The use of a well-written cheat sheet can be a great help here, and thankfully there are many good xpath ones. A very nice selection can be found <a href="http://bit.ly/28KxCoO">here</a>, with <a href="http://bit.ly/1UAmlS4">this color-coded one</a> being particularly useful.</p>
</div>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="A First Scrapy Spider"><div class="sect1" id="idm140319429021520">
<h1>A First Scrapy Spider</h1>

<p><a data-type="indexterm" data-primary="Scrapy library" data-secondary="spider production" id="SLspider6"></a><a data-type="indexterm" data-primary="spiders (Scrapy)" data-secondary="producing" id="spiders6"></a>Armed with a little xpath knowledge, let’s produce our first scraper aiming to get the country and link text for the winners (<a data-type="xref" href="#scrapy_wiki_list">Figure 6-2</a> A and B).</p>

<p>Scrapy calls its scrapers <em>spiders</em>, each of which is a Python module placed in the <em>spiders</em> directory of your project. We’ll call our first scraper <em>nwinner_list_spider.py</em>:</p>

<pre data-type="programlisting">.
├── nobel_winners
│   ├── __init__.py
│   ├── items.py
│   ├── pipelines.py
│   ├── settings.py
│   └── spiders
│       |── __init__.py
│       └── nwinners_list_spider.py &lt;---
└── scrapy.cfg</pre>

<p>Spiders are subclassed <code>scrapy.Spider</code> classes, and any placed in the <em>spiders</em> directory will be automatically detected by Scrapy and made accessible by name to the <code>scrapy</code> command.</p>

<p>The basic Scrapy spider shown in <a data-type="xref" href="#scrapy_spider">Example 6-2</a> follows a pattern you’ll be using with most of your spiders. First you subclass a Scrapy <code>item</code> to create fields for your scraped data (section A in <a data-type="xref" href="#scrapy_spider">Example 6-2</a>). You then create a named spider by subclassing <code>scrapy.Spider</code> (section B in <a data-type="xref" href="#scrapy_spider">Example 6-2</a>). You will use the spider’s name when calling <code>scrapy</code> from the command line. Each spider has a <code>parse</code> method, which deals with the HTTP requests to a list of start URLs contained in a <code>start_url</code> class attribute. In our case, the start URL is the Wikipedia page for Nobel laureates by country.</p>
<div id="scrapy_spider" data-type="example">
<h5><span class="label">Example 6-2. </span>A first Scrapy spider</h5>

<pre data-type="programlisting" data-code-language="python"><code class="c1"># nwinners_list_spider.py</code><code>
</code><code>
</code><code class="kn">import</code><code> </code><code class="nn">scrapy</code><code>
</code><code class="kn">import</code><code> </code><code class="nn">re</code><code>
</code><code class="c1"># A. Define the data to be scraped</code><code>
</code><code class="k">class</code><code> </code><code class="nc">NWinnerItem</code><code class="p">(</code><code class="n">scrapy</code><code class="o">.</code><code class="n">Item</code><code class="p">)</code><code class="p">:</code><code>
</code><code>    </code><code class="n">country</code><code> </code><code class="o">=</code><code> </code><code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">(</code><code class="p">)</code><code>
</code><code>    </code><code class="n">name</code><code> </code><code class="o">=</code><code> </code><code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">(</code><code class="p">)</code><code>
</code><code>    </code><code class="n">link_text</code><code> </code><code class="o">=</code><code> </code><code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">(</code><code class="p">)</code><code>
</code><code>
</code><code class="c1"># B Create a named spider</code><code>
</code><code class="k">class</code><code> </code><code class="nc">NWinnerSpider</code><code class="p">(</code><code class="n">scrapy</code><code class="o">.</code><code class="n">Spider</code><code class="p">)</code><code class="p">:</code><code>
</code><code>    </code><code class="sd">""" Scrapes the country and link text of the Nobel-winners. """</code><code>
</code><code>
</code><code>    </code><code class="n">name</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">nwinners_list</code><code class="s1">'</code><code>
</code><code>    </code><code class="n">allowed_domains</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="s1">'</code><code class="s1">en.wikipedia.org</code><code class="s1">'</code><code class="p">]</code><code>
</code><code>    </code><code class="n">start_urls</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code>
</code><code>        </code><code class="s2">"</code><code class="s2">http://en.wikipedia.org ... of_Nobel_laureates_by_country</code><code class="s2">"</code><code>
</code><code>    </code><code class="p">]</code><code>
</code><code>    </code><code class="c1"># C A parse method to deal with the HTTP response</code><code>
</code><code>     </code><code class="k">def</code><code> </code><code class="nf">parse</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code><code> </code><code class="n">response</code><code class="p">)</code><code class="p">:</code><code>
</code><code>
</code><code>        </code><code class="n">h2s</code><code> </code><code class="o">=</code><code> </code><code class="n">response</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'</code><code class="s1">//h2</code><code class="s1">'</code><code class="p">)</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO1-1" href="#callout_heavyweight_scraping_with_scrapy_CO1-1"><img src="1.png" alt="1" width="12" height="12"></a><code>
</code><code>
</code><code>        </code><code class="k">for</code><code> </code><code class="n">h2</code><code> </code><code class="ow">in</code><code> </code><code class="n">h2s</code><code class="p">:</code><code>
</code><code>            </code><code class="n">country</code><code> </code><code class="o">=</code><code> </code><code class="n">h2</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'</code><code class="s1">span[@class=</code><code class="s1">"</code><code class="s1">mw-headline</code><code class="s1">"</code><code class="s1">]</code><code class="s1">'</code><code>\
</code><code>            </code><code class="s1">'</code><code class="s1">text()</code><code class="s1">'</code><code class="p">)</code><code class="o">.</code><code class="n">extract</code><code class="p">(</code><code class="p">)</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO1-2" href="#callout_heavyweight_scraping_with_scrapy_CO1-2"><img src="2.png" alt="2" width="12" height="12"></a><code>
</code><code>            </code><code class="k">if</code><code> </code><code class="n">country</code><code class="p">:</code><code>
</code><code>                </code><code class="n">winners</code><code> </code><code class="o">=</code><code> </code><code class="n">h2</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'</code><code class="s1">following-sibling::ol[1]</code><code class="s1">'</code><code class="p">)</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO1-3" href="#callout_heavyweight_scraping_with_scrapy_CO1-3"><img src="3.png" alt="3" width="12" height="12"></a><code>
</code><code>                </code><code class="k">for</code><code> </code><code class="n">w</code><code> </code><code class="ow">in</code><code> </code><code class="n">winners</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'</code><code class="s1">li</code><code class="s1">'</code><code class="p">)</code><code class="p">:</code><code>
</code><code>                    </code><code class="n">text</code><code> </code><code class="o">=</code><code> </code><code class="n">w</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'</code><code class="s1">descendant-or-self::text()</code><code class="s1">'</code><code class="p">)</code><code>\
</code><code>                    </code><code class="o">.</code><code class="n">extract</code><code class="p">(</code><code class="p">)</code><code>
</code><code>                    </code><code class="k">yield</code><code> </code><code class="n">NWinnerItem</code><code class="p">(</code><code>
</code><code>                        </code><code class="n">country</code><code class="o">=</code><code class="n">country</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">name</code><code class="o">=</code><code class="n">text</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                        </code><code class="n">link_text</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1"> </code><code class="s1">'</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="n">text</code><code class="p">)</code><code>
</code><code>                        </code><code class="p">)</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO1-1" href="#co_heavyweight_scraping_with_scrapy_CO1-1"><img src="1.png" alt="1" width="12" height="12"></a></dt>
<dd><p>Gets all the <code>&lt;h2&gt;</code> headers on the page, most of which will be our target country titles.</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO1-2" href="#co_heavyweight_scraping_with_scrapy_CO1-2"><img src="2.png" alt="2" width="12" height="12"></a></dt>
<dd><p>Where possible, gets the text of the <code>&lt;h2&gt;</code> element’s child <code>&lt;span&gt;</code> with class <code>mw-headline</code>.</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO1-3" href="#co_heavyweight_scraping_with_scrapy_CO1-3"><img src="3.png" alt="3" width="12" height="12"></a></dt>
<dd><p>Gets the list of country winners.</p></dd>
</dl></div>

<p>The <code>parse</code> method in <a data-type="xref" href="#scrapy_spider">Example 6-2</a> receives the response from an HTTP request to the Wikipedia Nobel Prize page and yields Scrapy items, which are then converted to JSON objects and appended to the output file, a JSON array of objects.</p>

<p>Let’s run our first spider to make sure we’re correctly parsing and scraping our Nobel data. First navigate to the <em>nobel_winners</em> root directory (containing the <em>scrapy.cfg</em> file) of the scraping project. Let’s see what scraping spiders are available:</p>

<pre data-type="programlisting">$ scrapy list
nwinners_list</pre>

<p>As expected, we have one <code>nwinners_list</code> spider sitting in the <em>spiders</em> directory. To start it scraping, we use the <code>crawl</code> command and direct the output to a <em>nwinners.json</em> file. By default, we get a lot of Python logging information accompanying the crawl:</p>

<pre data-type="programlisting">$ scrapy crawl nwinners_list -o nobel_winners.json
2015- ... [scrapy] INFO: Scrapy started (bot: nobel_winners)
2015- ... [scrapy] INFO: ... features available: ssl, http11
...
2015- ... [nwinners_list] INFO: Closing spider (finished)
2015- ... [nwinners_list] INFO: Dumping Scrapy stats:
        {'downloader/request_bytes': 551,
         'downloader/request_count': 2,
         'downloader/request_method_count/GET': 2,
         'downloader/response_bytes': 45469,
         ...
         'item_scraped_count': 1075, <a class="co" id="co_heavyweight_scraping_with_scrapy_CO2-1" href="#callout_heavyweight_scraping_with_scrapy_CO2-1"><img src="1.png" alt="1" width="12" height="12"></a>
2015- ...  [nwinners_list] INFO: Spider closed (finished)</pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO2-1" href="#co_heavyweight_scraping_with_scrapy_CO2-1"><img src="1.png" alt="1" width="12" height="12"></a></dt>
<dd><p>We scraped 1,075 Nobel winners from the page.</p></dd>
</dl>

<p>The output of the scrapy <code>crawl</code> shows 1,075 items successfully <span class="keep-together">scraped</span>. Let’s look at our JSON output file to make sure things have gone according to plan:</p>

<pre data-type="programlisting">$ head nobel_winners.json
[{"country": "Argentina",
  "link_text": "C\u00e9sar Milstein , Physiology or Medicine,"\
  " 1984",
  "name": "C\u00e9sar Milstein"},
 {"country": "Argentina",
  "link_text": "Adolfo P\u00e9rez Esquivel , Peace, 1980",
  "name": "Adolfo P\u00e9rez Esquivel"},
  ...</pre>

<p>As you can see, we have an array of JSON objects with the four key fields present and correct.</p>

<p>Now that we have a spider that successfully scrapes the list data for all the Nobel winners on the page, let’s start refining it to grab all the data we are targeting for our Nobel Prize visualization (see <a data-type="xref" href="#scrapy_target_JSON">Example 6-1</a> and <a data-type="xref" href="#scrapy_targets">Figure 6-1</a>).</p>

<p>First, let’s add all the data we plan to scrape as fields to our <code>scrapy.Item</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="o">...</code>
<code class="k">class</code> <code class="nc">NWinnerItem</code><code class="p">(</code><code class="n">scrapy</code><code class="o">.</code><code class="n">Item</code><code class="p">):</code>
    <code class="n">name</code> <code class="o">=</code> <code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">()</code>
    <code class="n">link</code> <code class="o">=</code> <code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">()</code>
    <code class="n">year</code> <code class="o">=</code> <code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">()</code>
    <code class="n">category</code> <code class="o">=</code> <code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">()</code>
    <code class="n">country</code> <code class="o">=</code> <code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">()</code>
    <code class="n">gender</code> <code class="o">=</code> <code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">()</code>
    <code class="n">born_in</code> <code class="o">=</code> <code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">()</code>
    <code class="n">date_of_birth</code> <code class="o">=</code> <code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">()</code>
    <code class="n">date_of_death</code> <code class="o">=</code> <code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">()</code>
    <code class="n">place_of_birth</code> <code class="o">=</code> <code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">()</code>
    <code class="n">place_of_death</code> <code class="o">=</code> <code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">()</code>
    <code class="n">text</code> <code class="o">=</code> <code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">()</code>
<code class="o">...</code></pre>

<p>It’s also sensible to simplify the code a bit and use a dedicated function, <code>process_winner_li</code>,  to process the winners’ link text. We’ll pass a link selector and country name to it and return a dictionary containing the scraped data:</p>

<pre data-type="programlisting" data-code-language="python"><code class="o">...</code>
    <code class="k">def</code> <code class="nf">parse</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">response</code><code class="p">):</code>

        <code class="n">h2s</code> <code class="o">=</code> <code class="n">response</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'//h2'</code><code class="p">)</code>

        <code class="k">for</code> <code class="n">h2</code> <code class="ow">in</code> <code class="n">h2s</code><code class="p">:</code>
            <code class="n">country</code> <code class="o">=</code> <code class="n">h2</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'span[@class="mw-headline"]'</code>\
            <code class="n">text</code><code class="p">()</code><code class="s1">').extract()</code>
            <code class="k">if</code> <code class="n">country</code><code class="p">:</code>
                <code class="n">winners</code> <code class="o">=</code> <code class="n">h2</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'following-sibling::ol[1]'</code><code class="p">)</code>
                <code class="k">for</code> <code class="n">w</code> <code class="ow">in</code> <code class="n">winners</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'li'</code><code class="p">):</code>
                    <code class="n">wdata</code> <code class="o">=</code> <code class="n">process_winner_li</code><code class="p">(</code><code class="n">w</code><code class="p">,</code> <code class="n">country</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code>
                    <code class="o">...</code></pre>
<aside data-type="sidebar" epub:type="sidebar" class="pagebreak-before"><div class="sidebar" id="idm140319428704992">
<h5>Embracing Regexes</h5><blockquote>
<p>Some people, when confronted with a problem, think
“I know, I’ll use regular expressions.”   Now they have two problems.</p>
<p data-type="attribution">Jamie Zawinskie</p>
</blockquote>

<p>The preceding quote is a hoary old classic but does sum up how many people feel about <a href="https://en.wikipedia.org/wiki/Regular_expression">regular expressions (regexes)</a>. Regexes use a sequence of characters to define a search expression used for string matching. Both Python and JavaScript have built-in handling of them.</p>

<p>In Python, the <code>re</code> module provides a number of regex methods. A common task might be to find all the email addresses in a document, recognizing email strings by the form <em>foo@bar.com</em>. Let’s create a regex to find them, breaking down the process:<sup><a data-type="noteref" id="idm140319428234272-marker" href="ch06.html#idm140319428234272">2</a></sup></p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code> <code class="p">[</code><code class="mi">12</code><code class="p">]:</code> <code class="n">txt</code> <code class="o">=</code> <code class="s1">'Feel free to contact me at '</code>\
<code class="s1">' pyjdataviz@kyrandale.com with any feedback.'</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">13</code><code class="p">]:</code> <code class="n">re</code><code class="o">.</code><code class="n">findall</code><code class="p">(</code><code class="s-Affix">r</code><code class="s1">'[\w\.-]+@[\w\.-]+'</code><code class="p">,</code> <code class="n">txt</code><code class="p">)</code>
<code class="n">Out</code><code class="p">[</code><code class="mi">13</code><code class="p">]:</code> <code class="p">[</code><code class="s1">'pyjdataviz@kyrandale.com'</code><code class="p">]</code></pre>

<p>The <code>findall</code> method takes a regex string (with an <em>r</em> prepended) as its first argument and the text to search as its second. The email search pattern uses the following rules:</p>
<table>

<tbody>
<tr>
<td><p>\w</p></td>
<td><p>Matches an alphanumeric string containing numbers and upper and lowercase letters (regex shorthand is [0-9a-zA-Z_])</p></td>
</tr>
<tr>
<td><p>\</p></td>
<td><p>Escapes a special character</p></td>
</tr>
<tr>
<td><p>\.</p></td>
<td><p>Matches a dot</p></td>
</tr>
<tr>
<td><p>-</p></td>
<td><p>Matches a hyphen</p></td>
</tr>
<tr>
<td><p>+</p></td>
<td><p>Matches one or more of the square-bracketed strings</p></td>
</tr>
</tbody>
</table>

<p>Taken together, these rules match any two strings connected by @ and containing alphanumeric characters or dots or hyphens. This is obviously a pretty broad pattern (e.g., <code>.@.</code> would provide a match) that you might want to refine. For example, you could use <code>r'[\w\.-]@gmail.com</code> if you were searching for only Gmail addresses.</p>

<p>Although the syntax of regexes can be challenging at first, the fact is that web scraping is often about pattern-matching messy and underspecified data, and a regex is pretty much tailor-made for many of the jobs that crop up. You can probably hack your way around them, but embracing them a little will make your life that much easier, and the good news is that a little goes a long way. See <a data-type="xref" href="#scrapy_process_li">Example 6-3</a> for some examples.</p>
</div></aside>

<p>The <code>process_winner_li</code> method is shown in <a data-type="xref" href="#scrapy_process_li">Example 6-3</a>. A <code>wdata</code> dictionary is filled with information extracted from the winner’s <code>li</code> tag, using a couple of regexes to find the prize year and category.</p>
<div id="scrapy_process_li" data-type="example">
<h5><span class="label">Example 6-3. </span>Processing a winner’s list item</h5>

<pre data-type="programlisting" data-code-language="python"><code class="c1"># ...</code><code>
</code><code class="kn">import</code><code> </code><code class="nn">re</code><code>
</code><code class="n">BASE_URL</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">http://en.wikipedia.org</code><code class="s1">'</code><code>
</code><code class="c1"># ...</code><code>
</code><code class="k">def</code><code> </code><code class="nf">process_winner_li</code><code class="p">(</code><code class="n">w</code><code class="p">,</code><code> </code><code class="n">country</code><code class="o">=</code><code class="bp">None</code><code class="p">)</code><code class="p">:</code><code>
</code><code>    </code><code class="sd">"""
    Process a winner's &lt;li&gt; tag, adding country of birth or
    nationality, as applicable.
    """</code><code>
</code><code>    </code><code class="n">wdata</code><code> </code><code class="o">=</code><code> </code><code class="p">{</code><code class="p">}</code><code>
</code><code>
</code><code>    </code><code class="n">wdata</code><code class="p">[</code><code class="s1">'</code><code class="s1">link</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">BASE_URL</code><code> </code><code class="o">+</code><code> </code><code class="n">w</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'</code><code class="s1">a/@href</code><code class="s1">'</code><code class="p">)</code><code class="o">.</code><code class="n">extract</code><code class="p">(</code><code class="p">)</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO3-1" href="#callout_heavyweight_scraping_with_scrapy_CO3-1"><img src="1.png" alt="1" width="12" height="12"></a><code>
</code><code>
</code><code>    </code><code class="n">text</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1"> </code><code class="s1">'</code><code class="o">.</code><code class="n">join</code><code class="p">(</code><code class="n">w</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'</code><code class="s1">descendant-or-self::text()</code><code class="s1">'</code><code class="p">)</code><code>
</code><code>        </code><code class="o">.</code><code class="n">extract</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code>
</code><code>    </code><code class="c1"># get comma-delineated name and strip trailing whitespace</code><code>
</code><code>    </code><code class="n">wdata</code><code class="p">[</code><code class="s1">'</code><code class="s1">name</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">text</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s1">'</code><code class="s1">,</code><code class="s1">'</code><code class="p">)</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">strip</code><code class="p">(</code><code class="p">)</code><code>
</code><code>
</code><code>    </code><code class="n">year</code><code> </code><code class="o">=</code><code> </code><code class="n">re</code><code class="o">.</code><code class="n">findall</code><code class="p">(</code><code class="s1">'</code><code class="s1">\</code><code class="s1">d{4}</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">text</code><code class="p">)</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO3-2" href="#callout_heavyweight_scraping_with_scrapy_CO3-2"><img src="2.png" alt="2" width="12" height="12"></a><code>
</code><code>    </code><code class="k">if</code><code> </code><code class="n">year</code><code class="p">:</code><code>
</code><code>        </code><code class="n">wdata</code><code class="p">[</code><code class="s1">'</code><code class="s1">year</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="nb">int</code><code class="p">(</code><code class="n">year</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">)</code><code>
</code><code>    </code><code class="k">else</code><code class="p">:</code><code>
</code><code>        </code><code class="n">wdata</code><code class="p">[</code><code class="s1">'</code><code class="s1">year</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="mi">0</code><code>
</code><code>        </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">Oops, no year in </code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">text</code><code class="p">)</code><code>
</code><code>
</code><code>    </code><code class="n">category</code><code> </code><code class="o">=</code><code> </code><code class="n">re</code><code class="o">.</code><code class="n">findall</code><code class="p">(</code><code>
</code><code>            </code><code class="s1">'</code><code class="s1">Physics|Chemistry|Physiology or Medicine|Literature|</code><code class="s1">'</code><code>\
</code><code>            </code><code class="s1">'</code><code class="s1">Peace|Economics</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>                </code><code class="n">text</code><code class="p">)</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO3-3" href="#callout_heavyweight_scraping_with_scrapy_CO3-3"><img src="3.png" alt="3" width="12" height="12"></a><code>
</code><code>    </code><code class="k">if</code><code> </code><code class="n">category</code><code class="p">:</code><code>
</code><code>        </code><code class="n">wdata</code><code class="p">[</code><code class="s1">'</code><code class="s1">category</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">category</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code>
</code><code>    </code><code class="k">else</code><code class="p">:</code><code>
</code><code>        </code><code class="n">wdata</code><code class="p">[</code><code class="s1">'</code><code class="s1">category</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">'</code><code>
</code><code>        </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">Oops, no category in </code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">text</code><code class="p">)</code><code>
</code><code>
</code><code>    </code><code class="k">if</code><code> </code><code class="n">country</code><code class="p">:</code><code>
</code><code>        </code><code class="k">if</code><code> </code><code class="n">text</code><code class="o">.</code><code class="n">find</code><code class="p">(</code><code class="s1">'</code><code class="s1">*</code><code class="s1">'</code><code class="p">)</code><code> </code><code class="o">!=</code><code> </code><code class="o">-</code><code class="mi">1</code><code class="p">:</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO3-4" href="#callout_heavyweight_scraping_with_scrapy_CO3-4"><img src="4.png" alt="4" width="12" height="12"></a><code>
</code><code>            </code><code class="n">wdata</code><code class="p">[</code><code class="s1">'</code><code class="s1">country</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">'</code><code>
</code><code>            </code><code class="n">wdata</code><code class="p">[</code><code class="s1">'</code><code class="s1">born_in</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">country</code><code>
</code><code>        </code><code class="k">else</code><code class="p">:</code><code>
</code><code>            </code><code class="n">wdata</code><code class="p">[</code><code class="s1">'</code><code class="s1">country</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">country</code><code>
</code><code>            </code><code class="n">wdata</code><code class="p">[</code><code class="s1">'</code><code class="s1">born_in</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">'</code><code>
</code><code>
</code><code>    </code><code class="c1"># store a copy of the link's text string</code><code>
</code><code>    </code><code class="c1"># for any manual corrections</code><code>
</code><code>    </code><code class="n">wdata</code><code class="p">[</code><code class="s1">'</code><code class="s1">text</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">text</code><code>
</code><code>    </code><code class="k">return</code><code> </code><code class="n">wdata</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO3-1" href="#co_heavyweight_scraping_with_scrapy_CO3-1"><img src="1.png" alt="1" width="12" height="12"></a></dt>
<dd><p>To grab the <code>href</code> attribute from the list item’s <code>&lt;a&gt;</code> tag (<code>&lt;li&gt;&lt;a href=<em>/wiki…</em>&gt;[winner name]&lt;/a&gt;…</code>), we use the xpath attribute referent @.</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO3-2" href="#co_heavyweight_scraping_with_scrapy_CO3-2"><img src="2.png" alt="2" width="12" height="12"></a></dt>
<dd><p>Here, we use <code>re</code>, Python’s built-in regex library, to find the four-digit year strings in the list item’s text.</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO3-3" href="#co_heavyweight_scraping_with_scrapy_CO3-3"><img src="3.png" alt="3" width="12" height="12"></a></dt>
<dd><p>Another use of the regex library to find the Nobel prize category in the text.</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO3-4" href="#co_heavyweight_scraping_with_scrapy_CO3-4"><img src="4.png" alt="4" width="12" height="12"></a></dt>
<dd><p>An asterisk following the winner’s name is used to indicate that the country is the winner’s by birth—not nationality—at the time of the prize (e.g., <code>"William Lawrence Bragg*, Physics, 1915"</code> in the list for Australia).</p></dd>
</dl></div>

<p><a data-type="xref" href="#scrapy_process_li">Example 6-3</a> returns all the winners’ data available on the main Wikipedia Nobels by Country page—that is, the name, year, category, country (country of birth or country of nationality when awarded the prize), and a link to the individual winners’ pages. We’ll need to use this last information to get those biographical pages and use them to scrape our remaining target data (see <a data-type="xref" href="#scrapy_target_JSON">Example 6-1</a> and <a data-type="xref" href="#scrapy_targets">Figure 6-1</a>).<a data-type="indexterm" data-primary="" data-startref="spiders6" id="idm140319427772080"></a><a data-type="indexterm" data-primary="" data-startref="SLspider6" id="idm140319427769104"></a></p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Scraping the Individual Biography Pages"><div class="sect1" id="scrapy_indiv_bios">
<h1>Scraping the Individual Biography Pages</h1>

<p>The main Wikipedia Nobels by Country page gave us a lot of our target data, but the winner’s date of birth, date of death (where applicable), and gender are still to be scraped. It is hoped that this information is available, either implicitly or explicitly, on their biography pages (for nonorganization winners).  Now’s a good time to fire up Chrome’s Elements tab and take a look at those pages to work out how we’re going to extract the desired data.</p>

<p>We saw in the last chapter (<a data-type="xref" href="ch05.html#chapter_getting_data">Chapter 5</a>) that the visible information boxes on individual’s pages are not a reliable source of information and are often missing entirely. Until recently,<sup><a data-type="noteref" id="idm140319427764448-marker" href="ch06.html#idm140319427764448">3</a></sup> a hidden <code>persondata</code> table (see <a data-type="xref" href="#scrapy_persondata">Figure 6-4</a>) gave fairly reliable access to such information as place of birth, date of death, and the like. Unfortunately, this handy resource has been deprecated.<sup><a data-type="noteref" id="idm140319427762336-marker" href="ch06.html#idm140319427762336">4</a></sup> The good news is that this is part of an attempt to improve the categorization of biographical information by giving it a dedicated space in <a href="https://www.wikidata.org/wiki/Wikidata:Main_Page">Wikidata</a>, Wikipedia’s central storage for its structured data.</p>

<figure><div id="scrapy_persondata" class="figure">
<img src="dvpj_0604.png" alt="dvpj 0604" width="1333" height="438">
<h6><span class="label">Figure 6-4. </span>A Nobel Prize winner’s hidden persondata table</h6>
</div></figure>

<p>Examining Wikipedia’s biography pages with Chrome’s Elements tab shows a link to the relevant Wikidata item (see <a data-type="xref" href="#scrapy_wikidata_link">Figure 6-5</a>), which takes you to the biographical data held at <a href="https://www.wikidata.org"><em class="hyperlink">https://www.wikidata.org</em></a>. By following this link, we can scrape whatever we find there, which we hope will be the bulk of our target data—significant dates and places (see <a data-type="xref" href="#scrapy_target_JSON">Example 6-1</a>).</p>

<figure><div id="scrapy_wikidata_link" class="figure">
<img src="dvpj_0605.png" alt="dvpj 0605" width="698" height="478">
<h6><span class="label">Figure 6-5. </span>Hyperlink to the winner’s Wikidata</h6>
</div></figure>

<p>Following the link to Wikidata shows a page containing fields for the data we are looking for, such as the date of birth of our prize winner. As <a data-type="xref" href="#scrapy_wikidata">Figure 6-6</a> shows, the properties are embedded in a nest of computer-generated HTML, with related codes, which we can use as a scraping identifier (e.g., date of birth has the code <code>P569</code>).</p>

<figure><div id="scrapy_wikidata" class="figure">
<img src="dvpj_0606.png" alt="dvpj 0606" width="777" height="512">
<h6><span class="label">Figure 6-6. </span>Biographical properties at Wikidata</h6>
</div></figure>

<p>As <a data-type="xref" href="#scrapy_wikidata_xpath">Figure 6-7</a> shows, the actual data we want, in this case a date string, is contained in a further nested branch of HTML, within its respective property tag. By selecting the <code>div</code> and right-clicking, we can store the element’s xpath and use that to tell Scrapy how to get the data it contains.</p>

<figure><div id="scrapy_wikidata_xpath" class="figure">
<img src="dvpj_0607.png" alt="dvpj 0607" width="763" height="436">
<h6><span class="label">Figure 6-7. </span>Getting the xpath for a Wikidata property</h6>
</div></figure>

<p>Now that we have the xpaths necessary to find our scraping targets, let’s put it all together and see how Scrapy chains requests, allowing for complex, multipage scraping operations.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Chaining Requests and Yielding Data"><div class="sect1" id="idm140319427767904">
<h1>Chaining Requests and Yielding Data</h1>

<p>In this section we’ll see how to chain Scrapy requests, allowing us to follow hyperlinks, scraping data as we go. First let’s enable Scrapy’s page caching. While experimenting with xpath targets, we want to limit the number of calls to Wikipedia, and it’s good manners to store our fetched pages. Unlike some datasets out there, our Nobel Prize winners change but once a year.<sup><a data-type="noteref" id="idm140319427731136-marker" href="ch06.html#idm140319427731136">5</a></sup></p>








<section data-type="sect2" data-pdf-bookmark="Caching Pages"><div class="sect2" id="idm140319427730336">
<h2>Caching Pages</h2>

<p><a data-type="indexterm" data-primary="Scrapy library" data-secondary="caching web pages" id="idm140319427729088"></a>As you might expect, Scrapy has a <a href="http://bit.ly/1UAqGVp">sophisticated caching system</a> that gives you fine-grained control over your page caching (e.g., allowing you to choose between database or filesystem storage backends, how long before your pages are expired, etc.).  It is implemented as <a href="http://bit.ly/261CIhH">middleware</a> enabled in our project’s <code>settings.py</code> module. There are various options available but for the purposes of our Nobel scraping, simply setting <code>HTTPCACHE_ENABLED</code> to <code>True</code> will suffice:</p>

<pre data-type="programlisting" data-code-language="python"><code class="c1"># -*- coding: utf-8 -*-</code>

<code class="c1"># Scrapy settings for nobel_winners project</code>
<code class="c1">#</code>
<code class="c1"># This file contains only the most important settings by</code>
<code class="c1"># default. All the other settings are documented here:</code>
<code class="c1">#</code>
<code class="c1">#     http://doc.scrapy.org/en/latest/topics/settings.html</code>
<code class="c1">#</code>

<code class="n">BOT_NAME</code> <code class="o">=</code> <code class="s1">'nobel_winners'</code>

<code class="n">SPIDER_MODULES</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'nobel_winners.spiders'</code><code class="p">]</code>
<code class="n">NEWSPIDER_MODULE</code> <code class="o">=</code> <code class="s1">'nobel_winners.spiders'</code>

<code class="c1"># Crawl responsibly by identifying yourself</code>
<code class="c1"># (and your website) on the user-agent</code>
<code class="c1">#USER_AGENT = 'nobel_winners (+http://www.yourdomain.com)'</code>

<code class="n">HTTPCACHE_ENABLED</code> <code class="o">=</code> <code class="bp">True</code></pre>

<p>Check out the full range of Scrapy middleware <a href="http://bit.ly/1PypUlU">in Scrapy’s documentation</a>.</p>

<p>Having ticked the caching box, let’s see how to chain Scrapy requests.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Yielding Requests"><div class="sect2" id="idm140319427697712">
<h2>Yielding Requests</h2>

<p><a data-type="indexterm" data-primary="Scrapy library" data-secondary="yielding requests" id="SLyield6"></a>Our existing spider’s <code>parse</code> method cycles through the Nobel winners, using the <code>process_winner_li</code> method to scrape the country, name, year, category, and biography-hyperlink fields. We now want to use the biography hyperlinks to generate a Scrapy request that will fetch the bio-pages and send them to a custom method for scraping.</p>

<p>Scrapy implements a Pythonic pattern for chaining requests, using Python’s <code>yield</code> statement to create a generator,<sup><a data-type="noteref" id="idm140319427684352-marker" href="ch06.html#idm140319427684352">6</a></sup> allowing Scrapy to easily consume any extra page requests we make. <a data-type="xref" href="#scrapy_yield">Example 6-4</a> shows the pattern in action.</p>
<div id="scrapy_yield" data-type="example">
<h5><span class="label">Example 6-4. </span>Yielding a request with Scrapy</h5>

<pre data-type="programlisting" data-code-language="python"><code class="k">class</code><code> </code><code class="nc">NWinnerSpider</code><code class="p">(</code><code class="n">scrapy</code><code class="o">.</code><code class="n">Spider</code><code class="p">)</code><code class="p">:</code><code>
</code><code>    </code><code class="n">name</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">nwinners_full</code><code class="s1">'</code><code>
</code><code>    </code><code class="n">allowed_domains</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="s1">'</code><code class="s1">en.wikipedia.org</code><code class="s1">'</code><code class="p">]</code><code>
</code><code>    </code><code class="n">start_urls</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code>
</code><code>        </code><code class="s2">"</code><code class="s2">https://en.wikipedia.org/wiki/List_of_Nobel_laureates</code><code class="s2">"</code><code> </code><code>\
</code><code>        </code><code class="s2">"</code><code class="s2">_by_country</code><code class="s2">"</code><code>
</code><code>    </code><code class="p">]</code><code>
</code><code>
</code><code>    </code><code class="k">def</code><code> </code><code class="nf">parse</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code><code> </code><code class="n">response</code><code class="p">)</code><code class="p">:</code><code>
</code><code>        </code><code class="n">filename</code><code> </code><code class="o">=</code><code> </code><code class="n">response</code><code class="o">.</code><code class="n">url</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s1">'</code><code class="s1">/</code><code class="s1">'</code><code class="p">)</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code><code>
</code><code>
</code><code>        </code><code class="n">h2s</code><code> </code><code class="o">=</code><code> </code><code class="n">response</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'</code><code class="s1">//h2</code><code class="s1">'</code><code class="p">)</code><code>
</code><code>        </code><code class="k">for</code><code> </code><code class="n">h2</code><code> </code><code class="ow">in</code><code> </code><code class="nb">list</code><code class="p">(</code><code class="n">h2s</code><code class="p">)</code><code class="p">[</code><code class="p">:</code><code class="mi">2</code><code class="p">]</code><code class="p">:</code><code>
</code><code>            </code><code class="n">country</code><code> </code><code class="o">=</code><code> </code><code class="n">h2</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'</code><code class="s1">span[@class=</code><code class="s1">"</code><code class="s1">mw-headline</code><code class="s1">"</code><code class="s1">]/text()</code><code class="s1">'</code><code class="p">)</code><code>
</code><code>                      </code><code class="o">.</code><code class="n">extract</code><code class="p">(</code><code class="p">)</code><code>
</code><code>            </code><code class="k">if</code><code> </code><code class="n">country</code><code class="p">:</code><code>
</code><code>                </code><code class="n">winners</code><code> </code><code class="o">=</code><code> </code><code class="n">h2</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'</code><code class="s1">following-sibling::ol[1]</code><code class="s1">'</code><code class="p">)</code><code>
</code><code>                </code><code class="k">for</code><code> </code><code class="n">w</code><code> </code><code class="ow">in</code><code> </code><code class="n">winners</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'</code><code class="s1">li</code><code class="s1">'</code><code class="p">)</code><code class="p">:</code><code>
</code><code>                    </code><code class="n">wdata</code><code> </code><code class="o">=</code><code> </code><code class="n">process_winner_li</code><code class="p">(</code><code class="n">w</code><code class="p">,</code><code> </code><code class="n">country</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">)</code><code>
</code><code>                    </code><code class="n">request</code><code> </code><code class="o">=</code><code> </code><code class="n">scrapy</code><code class="o">.</code><code class="n">Request</code><code class="p">(</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO4-1" href="#callout_heavyweight_scraping_with_scrapy_CO4-1"><img src="1.png" alt="1" width="12" height="12"></a><code>
</code><code>                        </code><code class="n">wdata</code><code class="p">[</code><code class="s1">'</code><code class="s1">link</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                        </code><code class="n">callback</code><code class="o">=</code><code class="bp">self</code><code class="o">.</code><code class="n">parse_bio</code><code class="p">,</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO4-2" href="#callout_heavyweight_scraping_with_scrapy_CO4-2"><img src="2.png" alt="2" width="12" height="12"></a><code>
</code><code>                        </code><code class="n">dont_filter</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code><code>
</code><code>                    </code><code class="n">request</code><code class="o">.</code><code class="n">meta</code><code class="p">[</code><code class="s1">'</code><code class="s1">item</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">NWinnerItem</code><code class="p">(</code><code class="o">*</code><code class="o">*</code><code class="n">wdata</code><code class="p">)</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO4-3" href="#callout_heavyweight_scraping_with_scrapy_CO4-3"><img src="3.png" alt="3" width="12" height="12"></a><code>
</code><code>                    </code><code class="k">yield</code><code> </code><code class="n">request</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO4-4" href="#callout_heavyweight_scraping_with_scrapy_CO4-4"><img src="4.png" alt="4" width="12" height="12"></a><code>
</code><code>
</code><code>    </code><code class="k">def</code><code> </code><code class="nf">parse_bio</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code><code> </code><code class="n">response</code><code class="p">)</code><code class="p">:</code><code>
</code><code>        </code><code class="n">item</code><code> </code><code class="o">=</code><code> </code><code class="n">response</code><code class="o">.</code><code class="n">meta</code><code class="p">[</code><code class="s1">'</code><code class="s1">item</code><code class="s1">'</code><code class="p">]</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO4-5" href="#callout_heavyweight_scraping_with_scrapy_CO4-5"><img src="5.png" alt="5" width="12" height="12"></a><code>
</code><code>        </code><code class="o">.</code><code class="o">.</code><code class="o">.</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO4-1" href="#co_heavyweight_scraping_with_scrapy_CO4-1"><img src="1.png" alt="1" width="12" height="12"></a></dt>
<dd><p>Makes a request to the winner’s biography page, using the link (<code>wdata[<em>link</em>]</code>) scraped from <code>process_winner_li</code>.</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO4-2" href="#co_heavyweight_scraping_with_scrapy_CO4-2"><img src="2.png" alt="2" width="12" height="12"></a></dt>
<dd><p>Sets the callback function to handle the response.</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO4-3" href="#co_heavyweight_scraping_with_scrapy_CO4-3"><img src="3.png" alt="3" width="12" height="12"></a></dt>
<dd><p>Creates a Scrapy <code>Item</code> to hold our Nobel data and initializes it with the data just scraped from <code>process_winner_li</code>. This <code>Item</code> data is attached to the metadata of the request to allow any response access to it.</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO4-4" href="#co_heavyweight_scraping_with_scrapy_CO4-4"><img src="4.png" alt="4" width="12" height="12"></a></dt>
<dd><p>By yielding the request, we make the <code>parse</code> method a generator of consumable requests.</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO4-5" href="#co_heavyweight_scraping_with_scrapy_CO4-5"><img src="5.png" alt="5" width="12" height="12"></a></dt>
<dd><p>This method handles the callback from our bio-link request. In order to add scraped data to our Scrapy <code>Item</code>, we first retrieve it from the <code>response</code> metadata.</p></dd>
</dl></div>

<p>Our investigation of the Wikipedia pages in <a data-type="xref" href="#scrapy_indiv_bios">“Scraping the Individual Biography Pages”</a> showed that we need to locate a winner’s Wikidata link from their biography page and use it to generate a request. We will then scrape the date, place, and gender data from the response.</p>

<p><a data-type="xref" href="#scrapy_wikidata_source">Example 6-5</a> shows <code>parse_bio</code> and <code>parse_wikidata</code>, the two methods used to scrape our winners’ biographical data. <code>parse_bio</code> uses the scraped Wikidata link to request the Wikidata page, yielding the <code>request</code> as it in turn was yielded in the <code>parse</code> method. At the end of the request chain, <code>parse_wikidata</code> retrieves the item and fills in any of the fields available from Wikidata, eventually yielding the item to Scrapy.</p>
<div id="scrapy_wikidata_source" data-type="example">
<h5><span class="label">Example 6-5. </span>Parsing the winners’ biography data</h5>

<pre data-type="programlisting" data-code-language="python"><code class="c1"># ...</code><code>
</code><code>
</code><code>    </code><code class="k">def</code><code> </code><code class="nf">parse_bio</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code><code> </code><code class="n">response</code><code class="p">)</code><code class="p">:</code><code>
</code><code>
</code><code>        </code><code class="n">item</code><code> </code><code class="o">=</code><code> </code><code class="n">response</code><code class="o">.</code><code class="n">meta</code><code class="p">[</code><code class="s1">'</code><code class="s1">item</code><code class="s1">'</code><code class="p">]</code><code>
</code><code>        </code><code class="n">href</code><code> </code><code class="o">=</code><code> </code><code class="n">response</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s2">"</code><code class="s2">//li[@id=</code><code class="s2">'</code><code class="s2">t-wikibase</code><code class="s2">'</code><code class="s2">]/a/@href</code><code class="s2">"</code><code class="p">)</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO5-1" href="#callout_heavyweight_scraping_with_scrapy_CO5-1"><img src="1.png" alt="1" width="12" height="12"></a><code>
</code><code>               </code><code class="o">.</code><code class="n">extract</code><code class="p">(</code><code class="p">)</code><code>
</code><code>        </code><code class="k">if</code><code> </code><code class="n">href</code><code class="p">:</code><code>
</code><code>            </code><code class="n">request</code><code> </code><code class="o">=</code><code> </code><code class="n">scrapy</code><code class="o">.</code><code class="n">Request</code><code class="p">(</code><code class="n">href</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">,</code><code>\
</code><code>                          </code><code class="n">callback</code><code class="o">=</code><code class="bp">self</code><code class="o">.</code><code class="n">parse_wikidata</code><code class="p">,</code><code>\</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO5-2" href="#callout_heavyweight_scraping_with_scrapy_CO5-2"><img src="2.png" alt="2" width="12" height="12"></a><code>
</code><code>                          </code><code class="n">dont_filter</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code><code>
</code><code>            </code><code class="n">request</code><code class="o">.</code><code class="n">meta</code><code class="p">[</code><code class="s1">'</code><code class="s1">item</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">item</code><code>
</code><code>            </code><code class="k">yield</code><code> </code><code class="n">request</code><code>
</code><code>
</code><code>
</code><code>    </code><code class="k">def</code><code> </code><code class="nf">parse_wikidata</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code><code> </code><code class="n">response</code><code class="p">)</code><code class="p">:</code><code>
</code><code>
</code><code>        </code><code class="n">item</code><code> </code><code class="o">=</code><code> </code><code class="n">response</code><code class="o">.</code><code class="n">meta</code><code class="p">[</code><code class="s1">'</code><code class="s1">item</code><code class="s1">'</code><code class="p">]</code><code>
</code><code>        </code><code class="n">property_codes</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO5-3" href="#callout_heavyweight_scraping_with_scrapy_CO5-3"><img src="3.png" alt="3" width="12" height="12"></a><code>
</code><code>            </code><code class="p">{</code><code class="s1">'</code><code class="s1">name</code><code class="s1">'</code><code class="p">:</code><code class="s1">'</code><code class="s1">date_of_birth</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">code</code><code class="s1">'</code><code class="p">:</code><code class="s1">'</code><code class="s1">P569</code><code class="s1">'</code><code class="p">}</code><code class="p">,</code><code>
</code><code>            </code><code class="p">{</code><code class="s1">'</code><code class="s1">name</code><code class="s1">'</code><code class="p">:</code><code class="s1">'</code><code class="s1">date_of_death</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">code</code><code class="s1">'</code><code class="p">:</code><code class="s1">'</code><code class="s1">P570</code><code class="s1">'</code><code class="p">}</code><code class="p">,</code><code>
</code><code>            </code><code class="p">{</code><code class="s1">'</code><code class="s1">name</code><code class="s1">'</code><code class="p">:</code><code class="s1">'</code><code class="s1">place_of_birth</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">code</code><code class="s1">'</code><code class="p">:</code><code class="s1">'</code><code class="s1">P19</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">link</code><code class="s1">'</code><code class="p">:</code><code class="bp">True</code><code class="p">}</code><code class="p">,</code><code>
</code><code>            </code><code class="p">{</code><code class="s1">'</code><code class="s1">name</code><code class="s1">'</code><code class="p">:</code><code class="s1">'</code><code class="s1">place_of_death</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">code</code><code class="s1">'</code><code class="p">:</code><code class="s1">'</code><code class="s1">P20</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">link</code><code class="s1">'</code><code class="p">:</code><code class="bp">True</code><code class="p">}</code><code class="p">,</code><code>
</code><code>            </code><code class="p">{</code><code class="s1">'</code><code class="s1">name</code><code class="s1">'</code><code class="p">:</code><code class="s1">'</code><code class="s1">gender</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">code</code><code class="s1">'</code><code class="p">:</code><code class="s1">'</code><code class="s1">P21</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">link</code><code class="s1">'</code><code class="p">:</code><code class="bp">True</code><code class="p">}</code><code>
</code><code>        </code><code class="p">]</code><code>
</code><code>
</code><code>        </code><code class="n">p_template</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">//*[@id=</code><code class="s1">"</code><code class="s1">{code}</code><code class="s1">"</code><code class="s1">]/div[2]/div/div/div[2]</code><code class="s1">'</code><code> </code><code>\
</code><code>                     </code><code class="s1">'</code><code class="s1">/div[1]/div/div[2]/div[2]{link_html}/text()</code><code class="s1">'</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO5-4" href="#callout_heavyweight_scraping_with_scrapy_CO5-4"><img src="4.png" alt="4" width="12" height="12"></a><code>
</code><code>
</code><code>        </code><code class="k">for</code><code> </code><code class="n">prop</code><code> </code><code class="ow">in</code><code> </code><code class="n">property_codes</code><code class="p">:</code><code>
</code><code>
</code><code>            </code><code class="n">link_html</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">'</code><code>
</code><code>            </code><code class="k">if</code><code> </code><code class="n">prop</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="s1">'</code><code class="s1">link</code><code class="s1">'</code><code class="p">)</code><code class="p">:</code><code>
</code><code>                </code><code class="n">link_html</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">/a</code><code class="s1">'</code><code>
</code><code>            </code><code class="n">sel</code><code> </code><code class="o">=</code><code> </code><code class="n">response</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="n">p_template</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code>\</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO5-5" href="#callout_heavyweight_scraping_with_scrapy_CO5-5"><img src="5.png" alt="5" width="12" height="12"></a><code>
</code><code>                </code><code class="n">code</code><code class="o">=</code><code class="n">prop</code><code class="p">[</code><code class="s1">'</code><code class="s1">code</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">link_html</code><code class="o">=</code><code class="n">link_html</code><code class="p">)</code><code class="p">)</code><code>
</code><code>            </code><code class="k">if</code><code> </code><code class="n">sel</code><code class="p">:</code><code>
</code><code>                </code><code class="n">item</code><code class="p">[</code><code class="n">prop</code><code class="p">[</code><code class="s1">'</code><code class="s1">name</code><code class="s1">'</code><code class="p">]</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">sel</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">extract</code><code class="p">(</code><code class="p">)</code><code>
</code><code>
</code><code>        </code><code class="k">yield</code><code> </code><code class="n">item</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO5-6" href="#callout_heavyweight_scraping_with_scrapy_CO5-6"><img src="6.png" alt="6" width="12" height="12"></a></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO5-1" href="#co_heavyweight_scraping_with_scrapy_CO5-1"><img src="1.png" alt="1" width="12" height="12"></a></dt>
<dd><p>Extracts the link to Wikidata identified in <a data-type="xref" href="#scrapy_wikidata_link">Figure 6-5</a>.</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO5-2" href="#co_heavyweight_scraping_with_scrapy_CO5-2"><img src="2.png" alt="2" width="12" height="12"></a></dt>
<dd><p>Uses the Wikidata link to generate a request with our spider’s <code>parse_wikidata</code> as a callback to deal with the response.</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO5-3" href="#co_heavyweight_scraping_with_scrapy_CO5-3"><img src="3.png" alt="3" width="12" height="12"></a></dt>
<dd><p>These are the property codes we found earlier (see <a data-type="xref" href="#scrapy_wikidata">Figure 6-6</a>), with names corresponding to fields in our Scrapy item, <code>NWinnerItem</code>. Those with a <code>True</code> <code>link</code> attribute are contained in <code>&lt;a&gt;</code> tags.</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO5-4" href="#co_heavyweight_scraping_with_scrapy_CO5-4"><img src="4.png" alt="4" width="12" height="12"></a></dt>
<dd><p>The nasty, nested xpath for the Wikidata properties used to create this template comes straight from Chrome’s Elements tab (see <a data-type="xref" href="#scrapy_wikidata_xpath">Figure 6-7</a>). Here we create a Python string template, with the named variables <code>code</code> and <code>link_html</code> in curly brackets.  We can supply the <code>code</code> and <code>link_html</code> strings using this string’s <code>format</code> method.</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO5-5" href="#co_heavyweight_scraping_with_scrapy_CO5-5"><img src="5.png" alt="5" width="12" height="12"></a></dt>
<dd><p>We use the string template’s <a href="https://docs.python.org/2/library/string.html#format-string-syntax"><code>format</code> method</a> to create the xpath based on the required property codes, appending an <code>&lt;a&gt;</code> tag if the property is a link.</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO5-6" href="#co_heavyweight_scraping_with_scrapy_CO5-6"><img src="6.png" alt="6" width="12" height="12"></a></dt>
<dd><p>Finally we yield the item, which at this point should have all the target data available from Wikipedia.</p></dd>
</dl></div>

<p>With our request chain in place, let’s check that the spider is scraping our required data:</p>

<pre data-type="programlisting" data-code-language="bash"><code class="nv">$ </code>scrapy crawl nwinners_full
2015-... <code class="o">[</code>scrapy<code class="o">]</code> ... started <code class="o">(</code>bot: nobel_winners<code class="o">)</code>
...
2015-... <code class="o">[</code>nwinners_full<code class="o">]</code> DEBUG: Scraped from
         &lt;<code class="m">200</code> https://www.wikidata.org/wiki/Q155525&gt;
  <code class="o">{</code><code class="s1">'born_in'</code>: <code class="s1">''</code>,
   <code class="s1">'category'</code>: u<code class="s1">'Physiology or Medicine'</code>,
   <code class="s1">'date_of_birth'</code>: u<code class="s1">'8 October 1927'</code>,
   <code class="s1">'date_of_death'</code>: u<code class="s1">'24 March 2002'</code>,
   <code class="s1">'gender'</code>: u<code class="s1">'male'</code>,
   <code class="s1">'link'</code>: u<code class="s1">'http://en.wikipedia.org/wiki/C%C3%A9sar_Milstein'</code>,
   <code class="s1">'name'</code>: u<code class="s1">'C\xe9sar Milstein'</code>,
   <code class="s1">'country'</code>: u<code class="s1">'Argentina'</code>,
   <code class="s1">'place_of_birth'</code>: u<code class="s1">'Bah\xeda Blanca'</code>,
   <code class="s1">'place_of_death'</code>: u<code class="s1">'Cambridge'</code>,
   <code class="s1">'text'</code>: u<code class="s1">'C\xe9sar Milstein , Physiology or Medicine, 1984'</code>,
   <code class="s1">'year'</code>: 1984<code class="o">}</code>
2015-... <code class="o">[</code>nwinners_full<code class="o">]</code> DEBUG: Scraped from
         &lt;<code class="m">200</code> https://www.wikidata.org/wiki/Q193672&gt;
 <code class="o">{</code><code class="s1">'born_in'</code>: <code class="s1">''</code>,
  <code class="s1">'category'</code>: u<code class="s1">'Peace'</code>,
  <code class="s1">'date_of_birth'</code>: u<code class="s1">'1 November 1878'</code>,
  <code class="s1">'date_of_death'</code>: u<code class="s1">'5 May 1959'</code>,
  <code class="s1">'gender'</code>: u<code class="s1">'male'</code>,
  <code class="s1">'link'</code>: u<code class="s1">'http://en.wikipedia.org/wiki/Carlos_Saavedra_Lamas'</code>,
  ...</pre>

<p>Things are looking good. With the exception of the <code>born_in</code> field, which is dependent on a name in the main Wikipedia Nobel Prize winners list having an asterisk, we’re getting all the data we were targeting. This dataset is now ready to be cleaned by Pandas in the coming chapter.</p>

<p>Now that we’ve scraped our basic biographical data for the Nobel Prize winners, let’s go scrape our remaining targets, some biographical body text, and a picture of the great man or woman, where <span class="keep-together">available</span>.<a data-type="indexterm" data-primary="" data-startref="SLyield6" id="idm140319426872656"></a></p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Scrapy Pipelines"><div class="sect1" id="scrapy_pipelines">
<h1>Scrapy Pipelines</h1>

<p><a data-type="indexterm" data-primary="Scrapy library" data-secondary="pipelines in" id="SLpipeline6"></a><a data-type="indexterm" data-primary="pipelines (Scrapy library)" data-secondary="concept of" id="pipe6"></a>In order to add a little personality to our Nobel Prize visualization, it would be good to have a little biographical text and an image of the winner. Wikipedia’s biographical pages generally provide these things, so let’s go about scraping them.</p>

<p>Up to now, our scraped data has been text strings. In order to scrape images in their various formats, we need to use a Scrapy <em>pipeline</em>. <a href="http://doc.scrapy.org/en/latest/topics/item-pipeline.html">Pipelines</a> provide a way of post-processing the items we have <span class="keep-together">scraped</span>, and you can define any number of them.  You can write your own or take advantage of those already provided by Scrapy, such as the <code>ImagesPipeline</code> we’ll be using.</p>

<p>In its simplest form, a pipeline need only define a <code>process_item</code> method. This receives the scraped items and the spider object. Let’s write a little pipeline to reject genderless Nobel Prize winners (so we can omit prizes given to organizations rather than individuals) using our existing <code>nwinners_full</code> spider to deliver the items. First we add a <code>DropNonPersons</code> pipeline to the <code>pipelines.py</code> module of our project:</p>

<pre data-type="programlisting" data-code-language="python"><code class="c1"># nobel_winners/nobel_winners/settings.py</code><code>
</code><code>
</code><code class="c1"># Define your item pipelines here</code><code>
</code><code class="c1">#</code><code>
</code><code class="c1"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</code><code>
</code><code class="c1"># See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html</code><code>
</code><code>
</code><code class="kn">from</code><code> </code><code class="nn">scrapy.exceptions</code><code> </code><code class="kn">import</code><code> </code><code class="n">DropItem</code><code>
</code><code>
</code><code>
</code><code class="k">class</code><code> </code><code class="nc">DropNonPersons</code><code class="p">(</code><code class="nb">object</code><code class="p">)</code><code class="p">:</code><code>
</code><code>    </code><code class="sd">""" Remove non-person winners """</code><code>
</code><code>
</code><code>    </code><code class="k">def</code><code> </code><code class="nf">process_item</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code><code> </code><code class="n">item</code><code class="p">,</code><code> </code><code class="n">spider</code><code class="p">)</code><code class="p">:</code><code>
</code><code>        </code><code class="k">if</code><code> </code><code class="ow">not</code><code> </code><code class="n">item</code><code class="p">[</code><code class="s1">'</code><code class="s1">gender</code><code class="s1">'</code><code class="p">]</code><code class="p">:</code><code>               </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO6-1" href="#callout_heavyweight_scraping_with_scrapy_CO6-1"><img src="1.png" alt="1" width="12" height="12"></a><code>
</code><code>            </code><code class="k">raise</code><code> </code><code class="n">DropItem</code><code class="p">(</code><code class="s2">"</code><code class="s2">No gender for </code><code class="si">%s</code><code class="s2">"</code><code class="o">%</code><code class="n">item</code><code class="p">[</code><code class="s1">'</code><code class="s1">name</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>
</code><code>        </code><code class="k">return</code><code> </code><code class="n">item</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO6-2" href="#callout_heavyweight_scraping_with_scrapy_CO6-2"><img src="2.png" alt="2" width="12" height="12"></a></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO6-1" href="#co_heavyweight_scraping_with_scrapy_CO6-1"><img src="1.png" alt="1" width="12" height="12"></a></dt>
<dd><p>If our scraped item failed to find a gender property at Wikidata, it is probably an organization such as the Red Cross. Our visualization is focused on individual winners, so here we use <code>DropItem</code> to remove the item from our output stream.</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO6-2" href="#co_heavyweight_scraping_with_scrapy_CO6-2"><img src="2.png" alt="2" width="12" height="12"></a></dt>
<dd><p>We need to return the item to further pipelines or for saving by Scrapy.</p></dd>
</dl>

<p>As mentioned in the <code>pipelines.py</code> header, in order to add this pipeline to the spiders of our project, we need to register it in the <code>settings.py</code> module by adding it to a <code>dict</code> of pipelines and setting it to active (<code>1</code>):</p>

<pre data-type="programlisting" data-code-language="python"><code class="c1"># nobel_winners/nobel_winners/settings.py</code>

<code class="n">BOT_NAME</code> <code class="o">=</code> <code class="s1">'nobel_winners'</code>
<code class="n">SPIDER_MODULES</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'nobel_winners.spiders'</code><code class="p">]</code>
<code class="n">NEWSPIDER_MODULE</code> <code class="o">=</code> <code class="s1">'nobel_winners.spiders'</code>

<code class="n">HTTPCACHE_ENABLED</code> <code class="o">=</code> <code class="bp">True</code>
<code class="n">ITEM_PIPELINES</code> <code class="o">=</code> <code class="p">{</code><code class="s1">'nobel_winners.pipelines.DropNonPersons'</code><code class="p">:</code><code class="mi">1</code><code class="p">}</code></pre>

<p>Now that we’ve got the basic workflow for our pipelines, let’s add a useful one to our project.<a data-type="indexterm" data-primary="" data-startref="SLpipeline6" id="idm140319426632272"></a><a data-type="indexterm" data-primary="" data-startref="pipe6" id="idm140319426631424"></a></p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Scraping Text and Images with a Pipeline"><div class="sect1" id="scraping_bio">
<h1>Scraping Text and Images with a Pipeline</h1>

<p><a data-type="indexterm" data-primary="pipelines (Scrapy library)" data-secondary="scraping text and images with" id="PIPEtextimage6"></a>We now want to scrape the winners’ biography and photos (see <a data-type="xref" href="#scrapy_targets">Figure 6-1</a>), where available. We can scrape the biographical text using the same method as our last spider, but the photos are best dealt with by an image pipeline.</p>

<p>We could easily write our own pipeline to take a scraped image URL, request it from Wikipedia, and save to disk, but to do it properly requires a bit of care. For example, we would like to avoid reloading an image that was recently downloaded or hasn’t changed in the meantime. Some flexibility in specifying where to store the images is a useful feature. It would also be good to have the option of converting the images into a common format (e.g., JPG or PNG) or of generating thumbnails. Luckily, Scrapy provides an <code>ImagesPipeline</code> object with all this functionality and more. This is  one of its <a href="http://doc.scrapy.org/en/latest/topics/media-pipeline.html">media pipelines</a>, which includes a <code>FilesPipeline</code> for dealing with general files.</p>

<p>We could add the image and biography-text scraping to our existing <code>nwinners_full</code> spider, but that’s starting to get a little large, and segregating this character data from the more formal categories makes sense. So we’ll create a new spider called <code>nwinners_minibio</code> that will reuse parts of the previous spider’s <code>parse</code> method in order to loop through the Nobel winners.</p>

<p>As usual, when creating a Scrapy spider, our first job is to get the xpaths for our scraping targets—in this case, where available that’s the first part of the winners’ biographical text and a photograph of them. To do this, we fire up Chrome Elements and explore the HTML source of the biography pages looking for the targets shown in <a data-type="xref" href="#scrapy_crick">Figure 6-8</a>.</p>

<figure><div id="scrapy_crick" class="figure">
<img src="dvpj_0608.png" alt="dvpj 0608" width="954" height="706">
<h6><span class="label">Figure 6-8. </span>The target elements for our biography scraping: the first part of the biography (A) marked by a stop-point (B), and the winner’s photograph (C)</h6>
</div></figure>

<p>Investigating with Chrome Elements shows the biographical text (<a data-type="xref" href="#scrapy_crick">Figure 6-8</a> A) is contained in the first paragraphs of the <code>&lt;div&gt;</code> with id <code>mw-content-text</code>, captured by the xpath <code>//*[@id="mw-content-text"]/p</code>. There is an empty paragraph, which signals the stop-point (<a data-type="xref" href="#scrapy_crick">Figure 6-8</a> B) of the first section of the biography:</p>

<pre data-type="programlisting" data-code-language="html"><code class="nt">&lt;div</code> <code class="na">id=</code><code class="s">"mw-content-text"</code><code class="nt">&gt;</code>
  ...
  <code class="nt">&lt;p&gt;</code>...<code class="nt">&lt;/p&gt;</code>
  <code class="nt">&lt;p&gt;</code>...<code class="nt">&lt;/p&gt;</code>
  <code class="nt">&lt;p&gt;&lt;/p&gt;</code> <code class="nt">&lt;----</code> <code class="na">stop-point</code> <code class="na">--</code><code class="nt">&gt;</code>
  ...
<code class="nt">&lt;/div&gt;</code></pre>

<p>The exploration shows that the photos (<a data-type="xref" href="#scrapy_crick">Figure 6-8</a> C) are contained in a table of class <code>infobox</code> and are the only image tags (<code>&lt;img&gt;</code>) in that table:</p>

<pre data-type="programlisting" data-code-language="html"><code class="nt">&lt;table</code> <code class="na">class=</code><code class="s">"infobox vcard"</code><code class="nt">&gt;</code>
  ...
        <code class="nt">&lt;img</code> <code class="na">alt=</code><code class="s">"Francis Crick crop.jpg"</code> <code class="na">src=</code><code class="s">"//upload...</code> <code class="nt">/&gt;</code>
  ...
<code class="nt">&lt;/table&gt;</code></pre>

<p>The xpath <code>//table[contains(@class,"infobox")]//img/@src</code> will get the source address of the image.</p>

<p>As with our first spider, we first need to declare a Scrapy <code>Item</code> to hold our scraped data. We’ll scrape the bio-link and name of the winner, which we can use as identifiers for the image and text. We also need somewhere to store our <code>image-urls</code> (though we will only scrape one bio-image, I’ll cover the multiple-image use case), the resultant images references (a file path), and a <code>bio_image</code> field to store the particular image we’re interested in:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">scrapy</code>
<code class="kn">import</code> <code class="nn">re</code>

<code class="n">BASE_URL</code> <code class="o">=</code> <code class="s1">'http://en.wikipedia.org'</code>


<code class="k">class</code> <code class="nc">NWinnerItemBio</code><code class="p">(</code><code class="n">scrapy</code><code class="o">.</code><code class="n">Item</code><code class="p">):</code>
    <code class="n">link</code> <code class="o">=</code> <code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">()</code>
    <code class="n">name</code> <code class="o">=</code> <code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">()</code>
    <code class="n">mini_bio</code> <code class="o">=</code> <code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">()</code>
    <code class="n">image_urls</code> <code class="o">=</code> <code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">()</code>
    <code class="n">bio_image</code> <code class="o">=</code> <code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">()</code>
    <code class="n">images</code> <code class="o">=</code> <code class="n">scrapy</code><code class="o">.</code><code class="n">Field</code><code class="p">()</code>
<code class="o">...</code></pre>

<p>Now we reuse the scraping loop over our Nobel Prize winners (see <a data-type="xref" href="#scrapy_yield">Example 6-4</a> for details), this time yielding a request to our new <code>get_mini_bio</code> method, which will scrape the image URLs and bio text:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">class</code> <code class="nc">NWinnerSpiderBio</code><code class="p">(</code><code class="n">scrapy</code><code class="o">.</code><code class="n">Spider</code><code class="p">):</code>

    <code class="n">name</code> <code class="o">=</code> <code class="s1">'nwinners_minibio'</code>
    <code class="n">allowed_domains</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'en.wikipedia.org'</code><code class="p">]</code>
    <code class="n">start_urls</code> <code class="o">=</code> <code class="p">[</code>
        <code class="s2">"https://en.wikipedia.org/wiki/List_of_Nobel_"</code> \
        <code class="s2">"laureates_by_country"</code>
    <code class="p">]</code>

    <code class="k">def</code> <code class="nf">parse</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">response</code><code class="p">):</code>

        <code class="n">filename</code> <code class="o">=</code> <code class="n">response</code><code class="o">.</code><code class="n">url</code><code class="o">.</code><code class="n">split</code><code class="p">(</code><code class="s1">'/'</code><code class="p">)[</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code>
        <code class="n">h2s</code> <code class="o">=</code> <code class="n">response</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'//h2'</code><code class="p">)</code>

        <code class="k">for</code> <code class="n">h2</code> <code class="ow">in</code> <code class="n">h2s</code><code class="p">:</code>
            <code class="n">country</code> <code class="o">=</code> <code class="n">h2</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'span[@class="mw-headline"]'</code>\
            <code class="s1">'text()'</code><code class="p">)</code><code class="o">.</code><code class="n">extract</code><code class="p">()</code>
            <code class="k">if</code> <code class="n">country</code><code class="p">:</code>
                <code class="n">winners</code> <code class="o">=</code> <code class="n">h2</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'following-sibling::ol[1]'</code><code class="p">)</code>
                <code class="k">for</code> <code class="n">w</code> <code class="ow">in</code> <code class="n">winners</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'li'</code><code class="p">):</code>
                    <code class="n">wdata</code> <code class="o">=</code> <code class="p">{}</code>
                    <code class="n">wdata</code><code class="p">[</code><code class="s1">'link'</code><code class="p">]</code> <code class="o">=</code> <code class="n">BASE_URL</code> <code class="o">+</code> \
                    <code class="n">w</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code class="s1">'a/@href'</code><code class="p">)</code><code class="o">.</code><code class="n">extract</code><code class="p">()[</code><code class="mi">0</code><code class="p">]</code>
                    <code class="c1"># Process the winner's bio page with</code>
                    <code class="c1"># the get_mini_bio method</code>
                    <code class="n">request</code> <code class="o">=</code> <code class="n">scrapy</code><code class="o">.</code><code class="n">Request</code><code class="p">(</code><code class="n">wdata</code><code class="p">[</code><code class="s1">'link'</code><code class="p">],</code>
                                  <code class="n">callback</code><code class="o">=</code><code class="bp">self</code><code class="o">.</code><code class="n">get_mini_bio</code><code class="p">)</code>
                    <code class="n">request</code><code class="o">.</code><code class="n">meta</code><code class="p">[</code><code class="s1">'item'</code><code class="p">]</code> <code class="o">=</code> <code class="n">NWinnerItem</code><code class="p">(</code><code class="o">**</code><code class="n">wdata</code><code class="p">)</code>
                    <code class="k">yield</code> <code class="n">request</code></pre>

<p>Our <code>get_mini_bio</code> method will add any available photo URLs to the <code>image_urls</code> list and add all paragraphs of the biography up to the <code>&lt;p&gt;&lt;/p&gt;</code> stop-point to the item’s <code>mini_bio</code> field:</p>

<pre data-type="programlisting" data-code-language="python"><code class="o">.</code><code class="o">.</code><code class="o">.</code><code>
</code><code>    </code><code class="k">def</code><code> </code><code class="nf">get_mini_bio</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code><code> </code><code class="n">response</code><code class="p">)</code><code class="p">:</code><code>
</code><code>        </code><code class="sd">""" Get the winner's bio-text and photo """</code><code>
</code><code>
</code><code>        </code><code class="n">BASE_URL_ESCAPED</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">http:</code><code class="s1">\</code><code class="s1">/</code><code class="s1">\</code><code class="s1">/en.wikipedia.org</code><code class="s1">'</code><code>
</code><code>        </code><code class="n">item</code><code> </code><code class="o">=</code><code> </code><code class="n">response</code><code class="o">.</code><code class="n">meta</code><code class="p">[</code><code class="s1">'</code><code class="s1">item</code><code class="s1">'</code><code class="p">]</code><code>
</code><code>        </code><code class="n">item</code><code class="p">[</code><code class="s1">'</code><code class="s1">image_urls</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="p">]</code><code>
</code><code>        </code><code class="n">img_src</code><code> </code><code class="o">=</code><code> </code><code class="n">response</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code>\
</code><code>            </code><code class="s1">'</code><code class="s1">//table[contains(@class,</code><code class="s1">"</code><code class="s1">infobox</code><code class="s1">"</code><code class="s1">)]//img/@src</code><code class="s1">'</code><code class="p">)</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO7-1" href="#callout_heavyweight_scraping_with_scrapy_CO7-1"><img src="1.png" alt="1" width="12" height="12"></a><code>
</code><code>        </code><code class="k">if</code><code> </code><code class="n">img_src</code><code class="p">:</code><code>
</code><code>            </code><code class="n">item</code><code class="p">[</code><code class="s1">'</code><code class="s1">image_urls</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="s1">'</code><code class="s1">http:</code><code class="s1">'</code><code> </code><code class="o">+</code><code>\
</code><code>             </code><code class="n">img_src</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">extract</code><code class="p">(</code><code class="p">)</code><code class="p">]</code><code>
</code><code>        </code><code class="n">mini_bio</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">'</code><code>
</code><code>        </code><code class="n">paras</code><code> </code><code class="o">=</code><code> </code><code class="n">response</code><code class="o">.</code><code class="n">xpath</code><code class="p">(</code><code>
</code><code>            </code><code class="s1">'</code><code class="s1">//*[@id=</code><code class="s1">"</code><code class="s1">mw-content-text</code><code class="s1">"</code><code class="s1">]/p[text() or</code><code class="s1">'</code><code> </code><code>\
</code><code>            </code><code class="s1">'</code><code class="s1">normalize-space(.)=</code><code class="s1">"</code><code class="s1">"</code><code class="s1">]</code><code class="s1">'</code><code class="p">)</code><code class="o">.</code><code class="n">extract</code><code class="p">(</code><code class="p">)</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO7-2" href="#callout_heavyweight_scraping_with_scrapy_CO7-2"><img src="2.png" alt="2" width="12" height="12"></a><code>
</code><code>
</code><code>        </code><code class="k">for</code><code> </code><code class="n">p</code><code> </code><code class="ow">in</code><code> </code><code class="n">paras</code><code class="p">:</code><code>
</code><code>            </code><code class="k">if</code><code> </code><code class="n">p</code><code> </code><code class="o">==</code><code> </code><code class="s1">'</code><code class="s1">&lt;p&gt;&lt;/p&gt;</code><code class="s1">'</code><code class="p">:</code><code> </code><code class="c1"># the bio-intros stop-point </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO7-3" href="#callout_heavyweight_scraping_with_scrapy_CO7-3"><img src="3.png" alt="3" width="12" height="12"></a><code>
</code><code>                </code><code class="k">break</code><code>
</code><code>            </code><code class="n">mini_bio</code><code> </code><code class="o">+</code><code class="o">=</code><code> </code><code class="n">p</code><code>
</code><code>
</code><code>        </code><code class="c1"># correct for wiki-links</code><code>
</code><code>        </code><code class="n">mini_bio</code><code> </code><code class="o">=</code><code> </code><code class="n">mini_bio</code><code class="o">.</code><code class="n">replace</code><code class="p">(</code><code class="s1">'</code><code class="s1">href=</code><code class="s1">"</code><code class="s1">/wiki</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">href=</code><code class="s1">"</code><code class="s1">'</code><code>
</code><code>                       </code><code class="o">+</code><code> </code><code class="n">BASE_URL</code><code> </code><code class="o">+</code><code> </code><code class="s1">'</code><code class="s1">/wiki</code><code class="s1">'</code><code class="p">)</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO7-4" href="#callout_heavyweight_scraping_with_scrapy_CO7-4"><img src="4.png" alt="4" width="12" height="12"></a><code>
</code><code>        </code><code class="n">mini_bio</code><code> </code><code class="o">=</code><code> </code><code class="n">mini_bio</code><code class="o">.</code><code class="n">replace</code><code class="p">(</code><code class="s1">'</code><code class="s1">href=</code><code class="s1">"</code><code class="s1">#</code><code class="s1">'</code><code class="p">,</code><code>\
</code><code>         </code><code class="n">item</code><code class="p">[</code><code class="s1">'</code><code class="s1">link</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">+</code><code> </code><code class="s1">'</code><code class="s1">#</code><code class="s1">'</code><code class="p">)</code><code>
</code><code>        </code><code class="n">item</code><code class="p">[</code><code class="s1">'</code><code class="s1">mini_bio</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">mini_bio</code><code>
</code><code>        </code><code class="k">yield</code><code> </code><code class="n">item</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO7-1" href="#co_heavyweight_scraping_with_scrapy_CO7-1"><img src="1.png" alt="1" width="12" height="12"></a></dt>
<dd><p>Targets the first (and only) image in the table of class <code>infobox</code> and gets its source (<code>src</code>) attribute (e.g., <code>&lt;img src=<em>//upload.wikimedia.org/…/Max_Perutz.jpg</em>…</code>).</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO7-2" href="#co_heavyweight_scraping_with_scrapy_CO7-2"><img src="2.png" alt="2" width="12" height="12"></a></dt>
<dd><p>This xpath gets all the paragraphs in the <code>&lt;div&gt;</code> with id <code>mw-content-text</code>. If the paragraphs are empty (<code>text()</code> == <code>False</code>), then the <code>normalize-space(.)</code> command is used to force the contents of the paragraph (. represents the p-node in question) to an empty string. This is to make sure any empty paragraph matches the stop-point marking the end of the intro section of the biography.</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO7-3" href="#co_heavyweight_scraping_with_scrapy_CO7-3"><img src="3.png" alt="3" width="12" height="12"></a></dt>
<dd><p>Iterates through the available paragraphs, breaking on the empty paragraph stop-point.</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO7-4" href="#co_heavyweight_scraping_with_scrapy_CO7-4"><img src="4.png" alt="4" width="12" height="12"></a></dt>
<dd><p>Replaces Wikipedia’s internal hrefs (e.g., <em>/wiki/…</em>) with the full addresses our visualization will need.</p></dd>
</dl>

<p>With our bio-scraping spider defined, we need to create its complementary pipeline, which will take the image URLs scraped and convert them into saved images. We’ll use Scrapy’s <a href="http://bit.ly/1sK2cys">images pipeline</a> for this job.</p>

<p>The <code>ImagesPipeline</code> shown in <a data-type="xref" href="#scrapy_images_pipeline">Example 6-6</a> has two main methods, <code>get_media_requests</code>, which generates the requests for the image URLs, and <code>item_completed</code>, called after the requests have been <span class="keep-together">consumed</span>.</p>
<div id="scrapy_images_pipeline" data-type="example">
<h5><span class="label">Example 6-6. </span>Scraping images with the image pipeline</h5>

<pre data-type="programlisting" data-code-language="python"><code class="kn">import</code><code> </code><code class="nn">scrapy</code><code>
</code><code class="kn">from</code><code> </code><code class="nn">scrapy.contrib.pipeline.images</code><code> </code><code class="kn">import</code><code> </code><code class="n">ImagesPipeline</code><code>
</code><code class="kn">from</code><code> </code><code class="nn">scrapy.exceptions</code><code> </code><code class="kn">import</code><code> </code><code class="n">DropItem</code><code>
</code><code>
</code><code class="k">class</code><code> </code><code class="nc">NobelImagesPipeline</code><code class="p">(</code><code class="n">ImagesPipeline</code><code class="p">)</code><code class="p">:</code><code>
</code><code>
</code><code>    </code><code class="k">def</code><code> </code><code class="nf">get_media_requests</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code><code> </code><code class="n">item</code><code class="p">,</code><code> </code><code class="n">info</code><code class="p">)</code><code class="p">:</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO8-1" href="#callout_heavyweight_scraping_with_scrapy_CO8-1"><img src="1.png" alt="1" width="12" height="12"></a><code>
</code><code>
</code><code>        </code><code class="k">for</code><code> </code><code class="n">image_url</code><code> </code><code class="ow">in</code><code> </code><code class="n">item</code><code class="p">[</code><code class="s1">'</code><code class="s1">image_urls</code><code class="s1">'</code><code class="p">]</code><code class="p">:</code><code>
</code><code>            </code><code class="k">yield</code><code> </code><code class="n">scrapy</code><code class="o">.</code><code class="n">Request</code><code class="p">(</code><code class="n">image_url</code><code class="p">)</code><code>
</code><code>
</code><code>    </code><code class="k">def</code><code> </code><code class="nf">item_completed</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code><code> </code><code class="n">results</code><code class="p">,</code><code> </code><code class="n">item</code><code class="p">,</code><code> </code><code class="n">info</code><code class="p">)</code><code class="p">:</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO8-2" href="#callout_heavyweight_scraping_with_scrapy_CO8-2"><img src="2.png" alt="2" width="12" height="12"></a><code>
</code><code>
</code><code>        </code><code class="n">image_paths</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="n">x</code><code class="p">[</code><code class="s1">'</code><code class="s1">path</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="k">for</code><code> </code><code class="n">ok</code><code class="p">,</code><code> </code><code class="n">x</code><code> </code><code class="ow">in</code><code> </code><code class="n">results</code><code> </code><code class="k">if</code><code> </code><code class="n">ok</code><code class="p">]</code><code> </code><a class="co" id="co_heavyweight_scraping_with_scrapy_CO8-3" href="#callout_heavyweight_scraping_with_scrapy_CO8-3"><img src="3.png" alt="3" width="12" height="12"></a><code>
</code><code>        </code><code class="k">if</code><code> </code><code class="n">image_paths</code><code class="p">:</code><code>
</code><code>            </code><code class="n">item</code><code class="p">[</code><code class="s1">'</code><code class="s1">bio_image</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">image_paths</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code>
</code><code>
</code><code>        </code><code class="k">return</code><code> </code><code class="n">item</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO8-1" href="#co_heavyweight_scraping_with_scrapy_CO8-1"><img src="1.png" alt="1" width="12" height="12"></a></dt>
<dd><p>This takes any image URLs scraped by our <em>nwinners_minibio</em> spider and generates an HTTP request for their content.</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO8-2" href="#co_heavyweight_scraping_with_scrapy_CO8-2"><img src="2.png" alt="2" width="12" height="12"></a></dt>
<dd><p>After the image URL requests have been made, the results are delivered to the <code>item_completed</code> method.</p></dd>
<dt><a class="co" id="callout_heavyweight_scraping_with_scrapy_CO8-3" href="#co_heavyweight_scraping_with_scrapy_CO8-3"><img src="3.png" alt="3" width="12" height="12"></a></dt>
<dd><p>This Python list-comprehension filters the list of result tuples (of form <code>[(True, Image), (False, Image) …]</code>) for those that were successful and stores their file paths relative to the directory specified by the <code>IMAGES_STORE</code> variable in <code>settings.py</code>.</p></dd>
</dl></div>

<p>Now that we have the spider and pipeline defined, we just need to add the pipeline to our <code>settings.py</code> module and set the <code>IMAGES_STORE</code> variable to the directory we want to save the images in:</p>

<pre data-type="programlisting" data-code-language="python"><code class="c1"># nobel_winners/nobel_winners/settings.py</code>

<code class="o">...</code>
<code class="n">ITEM_PIPELINES</code> <code class="o">=</code> <code class="p">{</code><code class="s1">'nobel_winners.pipelines'</code>\
                  <code class="s1">'.NobelImagesPipeline'</code><code class="p">:</code><code class="mi">1</code><code class="p">}</code>
<code class="n">IMAGES_STORE</code> <code class="o">=</code> <code class="s1">'images'</code></pre>

<p>Let’s run our new spider from the <em>nobel_winners</em> root directory of our project, and check its output:</p>

<pre data-type="programlisting" data-code-language="bash"><code class="nv">$ </code>scrapy crawl nwinners_minibio -o minibios.json
...
2015-... DEBUG: Scraped from &lt;<code class="m">200</code> http:.../Albert_Claude&gt;
<code class="o">{</code><code class="s1">'image_urls'</code>: <code class="o">[]</code>,
  <code class="s1">'link'</code>: u<code class="s1">'http://en.wikipedia.org/wiki/Albert_Claude'</code>,
  <code class="s1">'mini_bio'</code>: u<code class="s1">'&lt;p&gt;&lt;b&gt;Albert Claude&lt;/b&gt; (24 August 1899...</code>
<code class="s1">    &lt;a href="http://en.wikipedia.org/wiki/Belgium"...&gt;Belgian</code>
<code class="s1">    &lt;a href="http://en.wikipedia.org/wiki/Medical_doctor"...&gt;</code>
<code class="s1">2015-... DEBUG: Scraped from &lt;200 http:.../Brian_P._Schmidt&gt;</code>
<code class="s1">{ '</code>bio_image<code class="s1">': '</code>full/a5f763b828006e704cb291411b8b643bfb91.jpg<code class="s1">',</code>
<code class="s1">  '</code>image_urls<code class="s1">': [u'</code>http://upload.wiki...Brian_Schmidt.jpg<code class="s1">'],</code>
<code class="s1">  '</code>link<code class="s1">': u'</code>http://en.wikipedia.org/wiki/Brian_P._Schmidt<code class="s1">',</code>
<code class="s1">  '</code>mini_bio<code class="s1">': u'</code>&lt;p&gt;&lt;b&gt;Brian Paul Schmidt&lt;/b&gt;...
...</pre>

<p>We can see that scraping Albert Claude’s biography page failed to turn up an image (a quick trip to Wikipedia confirms that it’s missing), but Brian Schmidt’s page came up just fine. The image was stored in <code>image_urls</code> and successfully processed, loading the JPG file stored in the <em>images</em> directory we specified with <code>IMAGE_STORE</code> with a relative path (<code>full/a5f763b828006e704cb291411b8b643bfb1<br>886c.jpg</code>). The filename is, conveniently enough, a <a href="https://en.wikipedia.org/wiki/Secure_Hash_Algorithm">SHA1 hash</a> of the image’s URL, which allows the image pipeline to check for existing images, enabling it to prevent redundant requests.</p>

<p>A quick listing of our images directory shows a nice array of Wikipedia Nobel Prize winner images, ready to be used in our web <span class="keep-together">visualization</span>:</p>

<pre data-type="programlisting" data-code-language="bash"><code class="nv">$ </code><code class="o">(</code>nobel_winners<code class="o">)</code> tree images
images
└── full
    ├── 0512ae11141584da1262661992a1b05dfb20dd52.jpg
    ├── 092a92689118c16b15b1613751af422439df2850.jpg
    ├── 0b6a8ca56e6ff115b7d30087df9c21da09684db1.jpg
    ├── 1197aa95299a1fec983b3dbdeaeb97a1f7e545c9.jpg
    ├── 1f6fb8e9e2241733da47328291b25bd1a78fa588.jpg
    ├── 272cf1b089c7a28ea0109ad8655bc3ef1c03fb52.jpg
    ├── 28dcc7978d9d5710f0c29d6dfcf09caa7e13a1d0.jpg
    ...</pre>

<p>As we’ll see in <a data-type="xref" href="ch15.html#chapter_building_viz">Chapter 15</a>, we will be placing these in the <em>static</em> folder of our web app, ready to be accessed via the winner’s <code>bio_image</code> field.</p>

<p>With our images and biography text to hand, we’ve successfully scraped all the targets we set ourselves at the beginning of the chapter (see <a data-type="xref" href="#scrapy_target_JSON">Example 6-1</a> and <a data-type="xref" href="#scrapy_targets">Figure 6-1</a>). Now, it’s time for a quick summary before moving on to clean this inevitably dirty data with help from Pandas.<a data-type="indexterm" data-primary="" data-startref="PIPEtextimage6" id="idm140319425714880"></a></p>








<section data-type="sect2" data-pdf-bookmark="Specifying Pipelines with Multiple Spiders"><div class="sect2" id="idm140319425713808">
<h2>Specifying Pipelines with Multiple Spiders</h2>

<p><a data-type="indexterm" data-primary="pipelines (Scrapy library)" data-secondary="specifying with multiple spiders" id="idm140319425712672"></a><a data-type="indexterm" data-primary="spiders (Scrapy)" data-secondary="specifying multiple" id="idm140319425711568"></a>The pipelines enabled in <code>settings.py</code> are applied to all spiders in our Scrapy project. Often, if you have a number of spiders, you’ll want to be able to specify which pipelines are applied on a spider-by-spider basis. There are a <a href="http://bit.ly/28KVdWr">number of ways</a> to achieve this, but the best I’ve seen is to use the spiders’ <code>custom_settings</code> class property to set the <code>ITEM_PIPELINES</code> dictionary instead of setting it in <code>settings.py</code>. In the case of our <code>nwinners_minibio</code> spider, this means adapting the <code>NWinnerSpiderBio</code> class like so:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">class</code> <code class="nc">NWinnerSpiderBio</code><code class="p">(</code><code class="n">scrapy</code><code class="o">.</code><code class="n">Spider</code><code class="p">):</code>
    <code class="n">name</code> <code class="o">=</code> <code class="s1">'nwinners_minibio'</code>
    <code class="n">allowed_domains</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'en.wikipedia.org'</code><code class="p">]</code>
    <code class="n">start_urls</code> <code class="o">=</code> <code class="p">[</code>
      <code class="s2">"http://en.wikipedia.org/wiki"</code>\
      <code class="s2">"List_of_Nobel_laureates_by_country"</code>
    <code class="p">]</code>

    <code class="n">custom_settings</code> <code class="o">=</code> <code class="p">{</code>
        <code class="s1">'ITEM_PIPELINES'</code><code class="p">:</code>\
        <code class="p">{</code><code class="s1">'nobel_winners.pipelines.NobelImagesPipeline'</code><code class="p">:</code><code class="mi">1</code><code class="p">}</code>
    <code class="p">}</code>

    <code class="c1"># ...</code></pre>

<p>Now the <code>NobelImagesPipeline</code> pipeline will only be applied while scraping the Nobel Prize winners’ biographies.<a data-type="indexterm" data-primary="" data-startref="Pscrapy6" id="idm140319425615184"></a><a data-type="indexterm" data-primary="" data-startref="WSscrapy6" id="idm140319425614272"></a><a data-type="indexterm" data-primary="" data-startref="NPVtextimage6" id="idm140319425613328"></a><a data-type="indexterm" data-primary="" data-startref="DCscrap6" id="idm140319425612384"></a></p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Summary"><div class="sect1" id="idm140319426629568">
<h1>Summary</h1>

<p>In this chapter we produced two Scrapy spiders that managed to grab the simple statistical dataset of our Nobel Prize winners plus some biographical text (and, where available, a photograph, to add some color to the stats). Scrapy is a powerful library that takes care of everything you could need in a full-fledged scraper. Although the workflow requires more effort to implement than doing some hacking with BeautifulSoup, Scrapy has far more power and comes into its own as your scraping ambitions increase. All Scrapy spiders follow the standard recipe demonstrated here, and the workflow should become routine after you program a few.</p>

<p>I hope this chapter has conveyed the rather hacky, iterative nature of scraping, and some of the quiet satisfaction that can be had when producing relatively clean data from the unpromising mound of stuff so often found on the Web. The fact is that now and for the foreseeable future, the large majority of interesting data (the fuel for the art and science of data visualization) is trapped in a form that is unusable for the web-based visualizations that this book focuses on. Scraping is, in this sense, an emancipating endeavor.</p>

<p>The data we scraped, much of it human-edited, will certainly have some errors—from badly formatted dates to categorical anomalies to missing fields. Making that data presentable is the focus of the next Pandas-based chapters. But first, we need a little introduction to Pandas and its building block, NumPy.</p>
</div></section>







<div data-type="footnotes"><p data-type="footnote" id="idm140319429037248"><sup><a href="ch06.html#idm140319429037248-marker">1</a></sup> See <a href="http://doc.scrapy.org/en/latest/intro/install.html">the Scrapy install docs</a> for platform-specific details.</p><p data-type="footnote" id="idm140319428234272"><sup><a href="ch06.html#idm140319428234272-marker">2</a></sup> There are some handy online tools for testing regexes, some of them programming-language-specific. <a href="http://www.pyregex.com/">Pyregex</a> is a good Python one, with a handy cheat sheet included.</p><p data-type="footnote" id="idm140319427764448"><sup><a href="ch06.html#idm140319427764448-marker">3</a></sup> The author got stung by this removal.</p><p data-type="footnote" id="idm140319427762336"><sup><a href="ch06.html#idm140319427762336-marker">4</a></sup> See <a href="http://bit.ly/1Pynkws">here</a> for an insight into Wikipedia dispute management.</p><p data-type="footnote" id="idm140319427731136"><sup><a href="ch06.html#idm140319427731136-marker">5</a></sup> Strictly speaking, there are edits being made continually by the Wikipedia community, but the fundamental details should be stable until the next set of prizes.</p><p data-type="footnote" id="idm140319427684352"><sup><a href="ch06.html#idm140319427684352-marker">6</a></sup> See <a href="https://www.jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/">Jeff Knupp’s blog, “Everything I Know About Python”</a>, for a nice rundown of Python generators and the use of <code>yield</code>.</p></div></div></section></div>



  <div class="t-sbo-prev sbo-prev sbo-nav-bottom">
  
    
      
        <a href="/library/view/data-visualization-with/9781491920565/ch05.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">5. Getting Data off the Web with Python</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-bottom">
  
    
      
        <a href="/library/view/data-visualization-with/9781491920565/part03.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">III. Cleaning and Exploring Data with Pandas</div>
        </a>
    
  
  </div>


        
    </section>
  </div>
<section class="sbo-saved-archives"></section>



          
          
  




    
    
      <div id="js-subscribe-nag" class="subscribe-nag clearfix trial-panel t-subscribe-nag">
        
        
          
          

          
            <p>You have 6 days left in your trial, Flankpeter. Subscribe today. <a href="/subscribe/" class="ga-active-trial-subscribe-nag">See pricing options.</a></p>
          
        
        

      </div>

    
    



        
      </div>
      




  <footer class="pagefoot t-pagefoot">
    <a href="#" class="icon-up"><div class="visuallyhidden">Back to top</div></a>
    <ul class='js-footer-nav'>
      
        <li><a class="t-recommendations-footer" href="/r/">Recommended</a></li>
      
      <li>
      
      <a class="t-queue-footer" href="/playlists/">Playlists</a>
      
      </li>
      
        <li><a class="t-recent-footer" href="/history/">History</a></li>
        <li><a class="t-topics-footer" href="/topics?q=*&limit=21">Topics</a></li>
      
      
        <li><a class="t-tutorials-footer" href="/tutorials/">Tutorials</a></li>
      
      <li><a class="t-settings-footer js-settings" href="/u/">Settings</a></li>
      <li class="full-support"><a href="https://www.safaribooksonline.com/public/support">Support</a></li>
      <li><a href="https://www.safaribooksonline.com/apps/">Get the App</a></li>
      <li><a href="/accounts/logout/">Sign Out</a></li>
    </ul>
    <span class="copyright">&#169; 2018 <a href="https://www.safaribooksonline.com" target="_blank">Safari</a>.</span>
    <a href="/terms/">Terms of Service</a> /
    <a href="/privacy/">Privacy Policy</a>
  </footer>




    

    <script src="/jsi18n/web/" charset="utf-8"></script>
    <script src="/library/jsi18n/appcache/" charset="utf-8"></script>
  </body>
</html>
